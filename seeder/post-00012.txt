Fakebook: ゼロから作るSNS その1 データベース設計とクエリ分析

SNSを構築する上で、堅牢かつスケーラブルなデータベースを設計することは最重要だ。この記事では、ユーザ数や投稿記事数がいくら増えてもO(log(N))の対数性能を維持するスキーマとクエリを実例を交えて紹介する。これがおそらくSNS設計の真髄である。DBMSにはPostgreSQLを用いるが、考え方は他のシステムを使っても同じだ。

[zu]

* 概要と方針

既にFakebookのプロトタイプは完成していて、ユーザ登録から画像管理から通知まで全ての機能が揃っていて、設計も実装も既に固まっている。そのデータベースのスキーマのER図を以下に示す。主なテーブルは三つで、ユーザを管理するusersテーブルと、各ユーザが投稿した記事を管理するpostsテーブルと、通知を管理するnotificationsテーブルである。その他のテーブルは、正規化と性能最適化の過程でその三つのテーブルから分離されたものだ。

[zu]

DBのスキーマを設計するにあたり、正規化と性能最適化について理解し区別する必要がある。正規化の目的は、データの多重管理を避けて、すなわち出所を一元化して、不整合が起きにくくすることだ。正規化を進めるとDBの保守性が良くなることが多いが、性能が良くなるとは限らず、むしろ悪化する可能性もある。一方で、性能最適化は、実際に実行するクエリの効率を上げるためにスキーマを変えることで、結果として正規形に違反するスキーマになることもある。多重管理が過ぎると不具合の温床になるし、一元化を追求すると実運用に耐えない性能になるので、両者のバランスを取ることが重要だ。

SNSの文脈では、DBに投げるクエリは2種類に大別して考える。リスト系のクエリと、個別レコード操作のクエリだ。重いのはリスト系の操作で、それがスケーラビリティを決めるので、リスト系クエリをいかに効率化するかを考えてDB設計することになる。今回の例では、ユーザのリスト表示で参照するデータはusersテーブルに集め、ユーザの詳細画面でしか表示しないデータはuser_detailsテーブルに逃がしている。同様に、投稿のリスト表示で参照するデータはpostsテーブルに集め、投稿の詳細画面でしか表示しないデータはpost_detailsテーブルに逃がしている。リスト系クエリで読み込むテーブルを小さくすると、参照局所性が上がり、ストレージ層の入出力のデータ量が減少し、各層のキャッシュが利きやすくなり、結果として性能が上がる。

適切なテーブル分割ができたら、あとはクエリに合わせてインデックスを貼るだけだ。リスト系クエリでの全ての絞り込み操作はインデックスのみを参照するように設計する必要がある。インデックスは参照局所性が高いが、主テーブルは、上述の最適化をもってしても、参照局所性は相対的に低くなる。なので、主テーブルを参照しても良いのは、絞り込みが終わってから、表示するレコードの分だけということにする。この方針に違反したクエリは潜在的にボトルネックになるので、そうならないようにクエリ毎の実行計画を確認しておくことが重要だ。

* Snowflake ID

個々のテーブルのスキーマを解説する前に、レコードのIDの採番方法について知ることが有益だ。Fakebookでは、Twitterが開発したSnowflake IDの変種を用いる。具体的には、44ビットで表現したミリ秒のタイムスタンプの後ろに、8ビットで表現したワーカーIDをつけ、その後ろに12ビットのシーケンス番号をつけた上で、全体を16進数の文字列に変換している。合計64ビットを16進数で表すと、"198C2E846EE00000" のような16文字になる。

固定桁のタイムスタンプを接頭させることで、文字列の辞書順で比較すると発番の時系列と順序が一致する。この特徴はUUIDv7でも同じだが、36文字も場所を取るUUIDに対して、Snowflake IDは16文字と短くて済むのが利点だ。それでいて、単一の発番器が同一ミリ秒に4096回の発番が可能で、256個まで発番器を同時稼働させられるので、実運用上の衝突のリスクはゼロにできる。そして、プライマリキーの順序が時系列と一致すると、created_atのような従属属性を参照しなくてもソートができるため、より効率的なクエリが書けるようになる。

効率を追求するなら、16進数など使わずに、Snowflake IDを64ビットの数値としてDBに入れた方が良い。二つの文字列を比較すると数10クロックかかるが、数値比較は1クロックでできる。しかし、現実的には比較関数のCPU負荷がボトルネックになることは稀なので、今回は分かりやすいように文字列として扱うことにした。

* usersテーブル

ユーザを管理するusersテーブルに着目しよう。その実際のスキーマは以下のものだ。

>|sql|
CREATE TABLE users (
  id VARCHAR(100) PRIMARY KEY,
  email VARCHAR(50) NOT NULL UNIQUE,
  nickname VARCHAR(50) NOT NULL,
  password VARCHAR(100) NOT NULL,
  is_admin BOOLEAN NOT NULL,
  snippet VARCHAR(4096) NOT NULL,
  avatar VARCHAR(100),
  ai_model VARCHAR(50) REFERENCES ai_models(name) ON DELETE SET NULL,
  created_at TIMESTAMPTZ NOT NULL,
  updated_at TIMESTAMPTZ,
  count_followers INT NOT NULL DEFAULT 0,
  count_followees INT NOT NULL DEFAULT 0,
  count_posts INT NOT NULL DEFAULT 0
);
CREATE INDEX idx_users_nickname_id ON users(LOWER(nickname) text_pattern_ops, nickname, id);
||<

プライマリキーであるidはSnowflake IDだ。ユーザ登録時に指定したメアドを使ってログイン操作を行うが、以後のユーザの識別は全てidを用いる。emailにはUNIQUE制約がついているので、自動的にインデックスが張られ、emailによる検索が効率化する。

ほとんどのメールサービスでは、メアドの大文字と小文字を区別しないので、emailは小文字に正規化して格納する。大文字と小文字を区別するサービスで大文字のメアドを使っている人は、確認メールが届かないので、このシステムを利用できないことになるが、仕方ない。もし大文字小文字の違いを許してしまうと、区別しないサーバでは、同じメアドで大量のアカウントが作れてしまう。

nicknameにはUNIQUE制約がないので、同一のニックネームのユーザが複数いることが許される。この点はTwitterのハンドルネームとは明確に異なる。名前の取り合いを避けるためにそうした。ユーザをニックネームで検索する機能があるので、nicknameにはインデックスを貼っている。大文字小文字の違いを無視して検索を効率化したいので、インデックス内の値は小文字に正規化している。また、idとの複合インデックスになっている。検索には必ず順序指定が伴うので、その順序として使われるidとの複合インデックスにすることで検索が効率化する。そうでないと該当の全件をソートすることになってしまう。

基本のキだが、パスワードはハッシュ化して保存している。ハッシュ値さえあれば、パスワードそのものを保管していなくても、「WHERE email = {input_email} AND password = hash({input_password})」というクエリでログイン処理は完遂できる。

count_followers、count_followees、count_postsは、それぞれ、自分をフォローしたユーザ数、自分がフォローしたユーザ数、自分が投稿した記事数を表している。フォロワーと記事はそれぞれuser_followsとpostsという別テーブルになっていて、他テーブルから導出可能な値を二重管理していることになる。PostgreSQLのストアドファンクションでそれらの自動更新がなされるようになっているので、アプリ側で複雑な処理を書かなくてもトランザクション内で整合性が保たれる。なお、これらの属性の存在は、他テーブルの集合演算の推移的従属は第6正規形までのルールには違反していないが、広い意味でのドメインキー正規形には違反している。それでも敢行しているのは、そうしないとまともな性能が出ないからだ。ユーザの一覧を表示する度に各ユーザのフォロワー数や投稿数を数え直していたら、すぐに破綻してしまうだろう。

is_adminは、管理者かどうかのフラグである。ガチなサービスであれば、権限を細かく分けて運用するべきなのだろうけども、管理しきれなくなるリスクもある。AWSやGCPのロールの管理で辟易しているので、それへのアンチテーゼとして、管理者ユーザと一般ユーザの2種類で済ませた。何でもできる管理者と、自分のリソースしか扱えない一般ユーザの区分けだけでも、SNSとしての運用はできる。

その他の属性は、表示用のものだ。snippetは、ユーザの自己紹介のスニペットで、Markdownを解析した後のJSON文字列が入っている。avatarは、アバター画像（アイコン）の保管場所を示す。通常はS3上のパスが入る。created_atとかupdated_atは、ユーザの作成日時と更新日時だ。created_atはSnowflake IDの生成時と同じタイムスタンプで生成しているため、両者の順序は確実に整合する。ai_modelは、AIエージェントが読んで自分の行動パターンを決めるのにも用いる。

ユーザ一覧画面で表示する属性は全てusersテーブルにあり、ユーザ詳細画面でのみ表示する属性はuser_detailsテーブルに逃している。

>|sql|
CREATE TABLE user_details (
  user_id VARCHAR(50) PRIMARY KEY,
  introduction VARCHAR(65535) NOT NULL,
  ai_personality VARCHAR(5000),
  FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE
);
||<

introductionは自己紹介の全文であり、Markdownの文字列が入っている。ai_personalityはプレーンテキストが入っている。この二つの属性はデータが大きくなりがちなので、それを分離することで、usersの性能が安定する。

* postsテーブル

投稿された記事を管理するpostsテーブルに着目しよう。その実際のスキーマは以下のものだ。

>|sql|
CREATE TABLE posts (
  id VARCHAR(50) PRIMARY KEY,
  snippet VARCHAR(4096) NOT NULL,
  owned_by VARCHAR(50) NOT NULL REFERENCES users(id) ON DELETE CASCADE,
  reply_to VARCHAR(50) REFERENCES posts(id) ON DELETE SET NULL,
  allow_likes BOOLEAN NOT NULL,
  allow_replies BOOLEAN NOT NULL,
  created_at TIMESTAMPTZ NOT NULL,
  updated_at TIMESTAMPTZ,
  count_likes INT NOT NULL DEFAULT 0,
  count_replies INT NOT NULL DEFAULT 0
);
CREATE INDEX idx_posts_owned_by_id ON posts(owned_by, id);
CREATE INDEX idx_posts_reply_to_id ON posts(reply_to, id);
CREATE INDEX idx_posts_root_id ON posts (id) WHERE reply_to IS NULL;
CREATE INDEX idx_posts_root_owned_by_id ON posts (owned_by, id) WHERE reply_to IS NULL;
||<

プライマリキーであるidはSnowflake IDだ。usersと同様にリストを返す全てのクエリは「ORDER BY id」をすることになり、その順序が時系列になるのは便利だ。

owned_byは、その投稿を書いたユーザのIDだ。ユーザ毎の投稿の一覧を出すクエリのために、当然それにインデックスを貼る必要がある。その際にもID順でデータを返すので、owned_byとidの複合インデックスにすべきだ。

reply_toは返信先の投稿IDだ。返信ではない投稿はreply_toにNULLを持つ。投稿毎の返信の一覧を出すクエリのために、当然それにIDとの複合インデックスを貼る必要がある。また、ログイン後のUIのデフォルト状態では、返信ではない投稿の一覧を出したい。そのクエリを効率化するため、NULL値に限定した、IDとの複合インデックスを作っている。

allow_likesとallow_repliesは、それぞれイイネと返信を受け付けるか否かを示している。ヘルプ記事などは多くのユーザに見られるだろうが、そこにイイネや返信をつけるスパム行為が予期されるため、任意のページのイイネや返信をブロックする機能は必須だ。

その他の属性は、表示用のものだ。snippetは、投稿本文のスニペットで、Markdownを解析した後のJSON文字列が入っている。created_atとupdated_atは、それぞれ作成時刻と更新時刻を意味する。作成時刻が表示したいのは自明だが、更新時刻も重要だ。イイネや返信を集めた後に内容を書き換えると悪戯や意図せぬ誤解の元になるため、少なくとも更新した事実を表示することで警戒を促すべきだ。

count_likesとcount_repliesは、それぞれイイネと返信の数を格納している。usersのcount_followersなどと同様に、ストアドファンクションで値を自動更新している。こちらもドメインキー正規形に違反しているが、投稿のリスト表示で毎回数えるわけにはいかないので、仕方がない。

投稿一覧画面で表示する属性は全てpostsテーブルにあり、投稿詳細画面でのみ表示する属性はpost_detailsテーブルに逃している。

>|sql|
CREATE TABLE post_details (
  post_id VARCHAR(50) PRIMARY KEY,
  content VARCHAR(65535) NOT NULL,
  FOREIGN KEY (post_id) REFERENCES posts(id) ON DELETE CASCADE
);
||<

contentは投稿記事の全文であり、Markdownの文字列が入っている。現状ではそれだけだ。この属性はデータが大きくなりがちなので、それを分離することで、postsの性能が安定する。

* MarkdownとJSONの使い分け

ユーザの自己紹介や投稿の記事の本文はMarkdownである。そのスニペットを作るのは、実はかなり複雑な問題を孕んでいる。単に文字列の長さで前方を抽出すると、マーキングの記号の途中で切られる可能性があり、構造が崩れてしまう。また、記号を文字数に数えると、本来の表示する長さで切ることができない。よって、MarkdownをAST（抽象構文木）として表して、それを走査しながら文字数を数えて、ノードの途中で打ち切る際には、中身の文字列のみを切って、ノード自体は生き残らせるという処理を行う。HTMLとして表示する際には、ASTをHTMLに変換すればよい。本文全体をHTMLに変換する際にも、全く同じ手順でASTを介して行う。これによって、本文がMarkdownなのに、表示が決して崩れないスニペットを実現できる。

本文をDBに保存する際には、Markdown文字列をそのまま保存する。ASTをJSONとして保存することもできるが、編集する際に再度Markdownに戻すためにはJSONからMarkdownに変換する完全逆写像を実現する必要があり、それを保証するのが大変だ。また、Markdownをそのまま保存した方がデータ量も小さい。

一方で、スニペットをDBに保存する際には、ASTをJSONとして保存する。スニペットをMarkdownに変換することも考えたが、ASTのままの方が無難だ。こちらも完全逆写像の保証が難しいのと、スニペットを編集することはないのが理由だ。ただし、`{"type":"element","tag":"p","text":"Hello World"}` のような文字列をそのまま保存すると効率が悪いので、JSONの体裁のまま圧縮を掛けている。具体的には、`{"T":"p","X":"Hello World"}` のように、構造の圧縮と属性名の辞書変換をかけている。これは非可逆圧縮なので、これによって表示が崩れることはない。

ところで、投稿のタイトルなどの構造をDBスキーマとして表現しないのも、設計の工夫のひとつだ。Markdownの中にはタイトル（H1ヘッダ）が本文に含まれる時もあるし、含まれない時もある。おそらく含まれないことの方が多い。構造に制約を持たせないことで、保守性を高めている。また、全文検索との相性も良い。本文を対象とする中間一致の全文検索（`content ILIKE '%xxx%'`）もサポートするが、タイトルと区別しないことで、クエリが単純になる。

なお、現状では、全文検索のために、pg_trgmなどのq-gramインデックスを貼っているわけではないので、全文検索のクエリはボトルネックになっている。インデックスを貼ればマシになるのは明らかなのにそうしていないのは、それによって更新処理が重くなるからだ。全文検索機能に関しては、バッチ処理でデータを抜き出して作った外部検索エンジンを使うのが無難だ。リアルタイム性が必要であれば、最新のデータだけを扱うオンメモリ検索と組み合わせればよい。検索エンジンにデータを流し込む際には、MarkdownからASTを構築すれば、タイトル等を属性として扱うなどの任意の後処理ができる。

* user_followsテーブル

ユーザ同士のフォロー関係を管理するuser_followsテーブルに着目しよう。その実際のスキーマは以下のものだ。

>|sql|
CREATE TABLE user_follows (
  follower_id VARCHAR(50) NOT NULL REFERENCES users(id) ON DELETE CASCADE,
  followee_id VARCHAR(50) NOT NULL REFERENCES users(id) ON DELETE CASCADE,
  created_at TIMESTAMPTZ NOT NULL,
  PRIMARY KEY (follower_id, followee_id)
);
CREATE INDEX idx_user_follows_followee_created_at ON user_follows (followee_id, created_at);
CREATE INDEX idx_user_follows_follower_created_at ON user_follows (follower_id, created_at);
||<

フォロイー（自分がフォローしているユーザ）の一覧と、フォロワー（自分をフォローしているユーザ）の一覧を見るためには、このテーブルが必要だ。usersテーブルにfollowersやfolloweesという属性を持たせて中に配列を入れるという運用もできなくはないが、第1正規形に違反する構造で運用すると確実に破綻するので、テーブル分割が必要だ。フォロワーとフォロイーのペアが主キーになっているので、一意性はそこで保証される。また、フォロイーとフォロワーの一覧をそれぞれ時系列で取得するクエリを効率化するためのインデックスが、created_atとの複合インデックスとして設けられている。

* post_tagsテーブル

投稿につけられるタグを管理するpost_tagsテーブルに着目しよう。その実際のスキーマは以下のものだ。

>||
CREATE TABLE post_tags (
  post_id VARCHAR(50) NOT NULL REFERENCES posts(id) ON DELETE CASCADE,
  name VARCHAR(50) NOT NULL,
  PRIMARY KEY (post_id, name)
);
CREATE INDEX idx_post_tags_name_post_id ON post_tags(name, post_id);
||<

記事を分類するにあたって、カテゴリとタグのどちらを使うべきかという議論がある。どちらも曖昧な概念ではあるが、その区別は重要だ。一般論として、カテゴリは、記事をフォルダ的に分類するものである。つまり、カテゴリを設ける場合、各記事は1つのカテゴリを必ず持つ。カテゴリがない記事は「その他」とかいったカテゴリをつけ、カテゴリが複数ありそうな記事も、便宜上、代表的なカテゴリを1つ選んでそれに所属させることになる。必然的に、カテゴリの種類を予め決めておいて、記事を執筆する際にどれかのカテゴリを選ぶというUXになる。一方で、タグは、記事を投稿する際に思いつきで決めるものだ。タグが無い記事があっても良いし、タグが複数個ある記事があっても良い。管理者不在で不特定多数が記事を投稿するSNSでは、カテゴリは運用しづらい。よって、タグを採用することになる。Twitterがタグ運用なのも同じ理由だろう。

タグは予め定義するものではなく、投稿の属性の位置づけだが、第1正規形を満たすためと、検索性を持たせるために、テーブルを分離する必要がある。一方で、タグをエンティティとしては扱わないので、タグにIDや作成日時のようなメタデータが付くことはない。よって、post_idとnameのペアを主キーとする。

タグ名で記事の一覧を取得するクエリを効率化するために、nameとpost_idの複合インデックスを張っている。複合インデックスにするのは、post_idでの順序付けを効率化するためだ。もしもpost_idがインデックスに含まれないと、nameに一致する投稿を全て取得してからソートすることになり、頻出のタグではすぐ破綻してしまうだろう。

* post_likesテーブル

投稿につけられるイイネを管理するpost_likesテーブルに着目しよう。その実際のスキーマは以下のものだ。

>|sql|
CREATE TABLE post_likes (
  post_id VARCHAR(50) NOT NULL REFERENCES posts(id) ON DELETE CASCADE,
  liked_by VARCHAR(50) NOT NULL REFERENCES users(id) ON DELETE CASCADE,
  created_at TIMESTAMPTZ NOT NULL,
  PRIMARY KEY (post_id, liked_by)
);
CREATE INDEX idx_post_likes_post_id_created_at ON post_likes(post_id, created_at);
CREATE INDEX idx_post_likes_liked_by_created_at ON post_likes(liked_by, created_at);
||<

個々の記事にイイネをつけたユーザの一覧を出すクエリを効率化すべく、post_idとcreated_atの複合インデックスが貼られている。これもソートを省く必要性のために存在する。また、自分がイイネした記事の一覧ができると、ブックマーク的に使えて便利だ。そのクエリを効率化するために、liked_byとcreated_atの複合インデックスも貼られている。

* event_logsテーブルとnotificationsテーブル

自分がフォローされたり、自分の投稿がイイネされたり、自分の投稿に返信をもらったりした場合、その通知を受け取る機能がある。それらの個々のイベントを全て通知されても鬱陶しいので、通知は日付とリソースの単位でまとめられる。「18 people including Alice, Bob, Nancy have given likes to your post "..." (2025-08-22)」みたいな通知カードになる。ユーザが個々の通知カードをクリックすると、未読状態から既読状態になる。

以上の要件を満たすため、まずはフォローとイイネと返信のイベントを、event_logsテーブルに入れる。そのスキーマは以下のものだ。

>|sql|
CREATE TABLE event_logs (
  partition_id SMALLINT NOT NULL,
  event_id BIGINT NOT NULL,
  payload JSONB NOT NULL,
  PRIMARY KEY (partition_id, event_id),
  UNIQUE (event_id)
);
||<

partition_idは、通知先のユーザIDに対する256の剰余で、[0,255] の値を持つ。event_idはイベント発生時刻を元にしたSnowflake IDだ。partition_idとevent_idの複合キーが主キーであり、勝手にインデックスが張られる。よって、特定のpartition_idに属するレコードをevent_idの昇順で取得するクエリが効率化する。payloadにはイベントの内容のJSONが入っている。例を示す。

>||
{"type": "follow", "followeeId": "9901000000000001", "followerId": "0001000000000003"}
{"type": "like", "postId": "9902500000001000", "userId": "0001000000000003"}
{"type": "reply", "postId": "198D9E3364600000", "userId": "0001000000000004", "replyToPostId": "9902500000001000"}
||<

イベントログを読み取るワーカーは複数居て、並列処理を行う。各ワーカーは自分が担当するpartition_idの範囲を知っていて、各パーティションを順番に処理する。ワーカーは0.5秒ごとにDBをポーリングして、担当の各パーティションで最大1000個のイベントを読み込む。したがって、各パーティションで最後に読んだIDを記録するために、event_log_cursorsテーブルを用意する。

>|sql|
CREATE TABLE event_log_cursors (
  consumer VARCHAR(50) NOT NULL,
  partition_id SMALLINT NOT NULL,
  last_event_id BIGINT NOT NULL DEFAULT 0,
  updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
  PRIMARY KEY (consumer, partition_id)
);
||<

consumerはワーカーの種類を識別するためにあるが、現状では "notification" しかない。それとpartition_idの複合キーが主キーなので、両者を指定すると効率的にレコードが取得できる。値として重要なのはlast_event_idだけだ。これは最後に処理したevent_idが入っていて、それより大きいIDのイベントログから読み始めれば良いとわかる。updated_atは追跡用の飾りだ。

読み出したイベントは、各ユーザの各リソースの各日を単位としてまとめて通知レコードになる。それを格納するのがnotificationsテーブルだ。

>|sql|
CREATE TABLE notifications (
  user_id VARCHAR(50) NOT NULL REFERENCES users(id) ON DELETE CASCADE,
  slot VARCHAR(50) NOT NULL,
  term VARCHAR(50) NOT NULL,
  is_read BOOLEAN NOT NULL DEFAULT FALSE,
  payload JSONB NOT NULL,
  updated_at TIMESTAMPTZ NOT NULL,
  created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
  PRIMARY KEY (user_id, slot, term)
);
CREATE INDEX idx_notifications_user_read_ts ON notifications(user_id, is_read, updated_at);
CREATE INDEX idx_notifications_created_at ON notifications(created_at);
||<

ユーザはuser_idで識別する。slotはリソース種別を表し、ユーザ自身が対象であるフォローでは「follow」という決め打ちの値で、投稿が対象であれば「like:{postId}」や「reply:{postId}」の形式の値になる。termはローカル時間の日付だ。スキーマ上は日付じゃなくても適当な期間ラベルをつけられるようになっている。is_readは未読既読の管理フラグで、updated_atとcreated_atは更新時刻と作成時刻だ。user_idとis_readとupdated_atの複合インデックスがあることで、各ユーザの既読通知の一覧と未読通知の一覧を効率的に取得できる。

通知のpayloadはJSONデータであり、その通知レコードに関わるユーザ数や投稿数とともに、最新10件の履歴を入れる。例を示す。

>||
follow => {"records": [{"ts": 1756002248514, "userId": "0001000000000004"}, {"ts": 1756002138545, "userId": "0001000000000003"}], "countUsers": 2}
like => {"records": [{"ts": 1756002187871, "userId": "0001000000000004"}, {"ts": 1756002077724, "userId": "0001000000000003"}], "countUsers": 2}
reply => {"records": [{"ts": 1756002203216, "postId": "198D9E3364600000", "userId": "0001000000000004"}, {"ts": 1756002097802, "postId": "198D9E19A8700000", "userId": "0001000000000003"}, {"ts": 1756002094769, "postId": "198D9E18EAE00000", "userId": "0001000000000003"}], "countPosts": 3, "countUsers": 2}
||<

event_logsテーブルとnotificationsテーブルは急速に肥大化するので、古いレコードを定期的に削除する必要がある。通知作成のワーカーがその処理を行う。event_logsに関しては、event_idから日付を逆算して発生から90日以上のものを削除する。notificationsに関しては、created_atが90日以前のものを削除する。ここでupdated_atを基準にしない方が良い。updated_atはイイネの度に更新されるので、それにインデックスを貼ると更新負荷が高い。

* その他のテーブル

ai_modelsテーブルとai_actionsテーブルは、存在してはいるが、現状では全く使っていない。ai_modelsは、AIエージェントを動かすAIモデル毎に、入出力コストなどのメタデータを記録するものだ。ai_actionsは、AIエージェントの各々が、自分が過去にどのような動作をしたかを記録し、記憶の導線とするものだ。これはJSONのスキーマレスDBとして運用し、雑多な情報を入れまくることになるだろう。詳細の仕様に付いては追って詰めていく。

移行は、Fakebookの運用上でデータベースに発行されるクエリについて分析していく。SQLの具体例を示し、その計算量を解析し、実際の実行計画を見て確認する。

* listPostsLite

全ての投稿の中から最新20件を取り出す処理を考える。バックエンドのpostsService.listPostsLiteというメソッドでそれは実装されている。デフォルトでは返信以外の投稿を一覧するため、reply_toがNULLであるという条件をつける。実際のクエリは以下のものだ。

>|sql|
SELECT
  p.id, p.owned_by, p.reply_to,
  p.allow_likes, p.allow_replies, p.created_at, p.updated_at
FROM posts p
WHERE reply_to IS NULL
ORDER BY p.id DESC OFFSET 0 LIMIT 20;
||<

postsテーブルには、reply_toがNULLのレコードだけを対象としたIDの部分インデックスが設けられているため、そのインデックスを引くだけで処理が完了する。全ての投稿数をPと置くと、計算量はO(log(P))で済む。これは、Pが莫大になっても性能に問題が出ないことを意味している。

PostgreSQLでは、クエリごとの実行計画をEXPLAIN文で調べることができる。以下の出力が得られる。インデックスを使って済むと言っている。推定3021件のレコードを持つインデックスを逆向きに操作して、20件がヒットした段階で処理を打ち切ることが示唆されている。つまりめちゃくちゃ効率的に動くということだ。

>||
Limit (cost=0.28..3.56 rows=20 width=96)
 -> Index Scan Backward using idx_posts_root_id on posts p (cost=0.28..496.23 rows=3021 width=96)
||<

* listPosts

実運用上は、各投稿の著者のユーザIDを名前に解決したり、各投稿につけられたタグ情報を結果に含めるために、別のテーブルをJOINすることになる。それを実装しているのが、listPostsメソッドだ。reply_toがNULLであるという条件をつけると、実際のクエリは以下のものになる。

>|sql|
SELECT
  p.id, p.snippet, p.owned_by, p.reply_to,
  p.allow_likes, p.allow_replies, p.created_at, p.updated_at,
  u.nickname AS owner_nickname, pu.nickname AS reply_to_owner_nickname,
  p.count_replies AS count_replies, p.count_likes AS count_likes,
  ARRAY(SELECT pt2.name FROM post_tags pt2
    WHERE pt2.post_id = p.id ORDER BY pt2.name) AS tags
FROM posts p
JOIN users u ON p.owned_by = u.id
LEFT JOIN posts parent_post ON p.reply_to = parent_post.id
LEFT JOIN users pu ON parent_post.owned_by = pu.id
WHERE p.reply_to IS NULL
ORDER BY p.id DESC OFFSET 0 LIMIT 20;
||<

listPostsLiteの場合と同様にインデックスが使われて、結果を返却するはずだ。その過程で、post_tagsテーブルとusersテーブルを結合している。タグに関しては返却の各行に対応して投稿IDが一致するタグをサブクエリで調べて取得して埋め込んでいる。ユーザ名に関しては、owned_byのIDをユーザ名に解決するためと、reply_toの投稿のowned_byのIDをユーザ名に解決するために、2回に分けてJOINしている。

これの計算量を考えよう。全ユーザ数をUと置き、全投稿数をPと置く。タグの数はおそらく投稿数の1%くらいの数になるだろうが、Pに比例するのでPとして扱う。まず、該当の投稿のリストを得るのに、インデックスが利けば、O(log(P))+O(20)の計算量がかかる。20は定数なので消えて、O(log(P))になる。そして、ヒットした20件の各々に対し、タグとユーザ名を解決する。インデックスが利けば、タグ取得はO(20\*log(P))で、ユーザ名取得はO(20\*log(U))だ。20は定数なので消えて、O(log(P))とO(log(U))になる。UはPよりも十分に少ないと仮定すると、全体の支配項はO(log(P))ということになる。つまり、計算量はlistPostsの時と同じである。

EXPLAIN文で実行計画を調べると、以下の出力が得られる。投稿でヒットしたレコードの各々に対して処理を行うNested Loopがあり、そこでJOINの処理を行っている。結合先のテーブルからデータを取り出すにあたっては全てインデックスが使われ、一部はキャッシュも使われていて、DB本体のシーケンシャルスキャン（Seq Scan）やインデックスのシーケンシャルスキャン（Filter）がひとつもなく、全てがインデックスの条件付き絞り込み（Index Cond）の理想的な処理になっていることがわかる。

>||
Limit (cost=1.14..106.13 rows=20 width=150)
 -> Nested Loop Left Join (cost=1.14..15858.95 rows=3021 width=150)
    -> Nested Loop Left Join (cost=0.86..2073.97 rows=3021 width=128)
       -> Nested Loop (cost=0.57..1474.58 rows=3021 width=111)
          -> Index Scan Backward using idx_posts_root_id on posts p (cost=0.28..496.23 rows=3021 width=104)
          -> Memoize (cost=0.29..0.91 rows=1 width=24)
             Cache Key: p.owned_by
             Cache Mode: logical
             -> Index Scan using users_pkey on users u (cost=0.28..0.90 rows=1 width=24)
                Index Cond: ((id)::text = (p.owned_by)::text)
       -> Memoize (cost=0.29..0.54 rows=1 width=34)
          Cache Key: p.reply_to
          Cache Mode: logical
          -> Index Scan using posts_pkey on posts parent_post (cost=0.28..0.53 rows=1 width=34)
             Index Cond: ((id)::text = (p.reply_to)::text)
    -> Memoize (cost=0.29..0.67 rows=1 width=24)
       Cache Key: parent_post.owned_by
       Cache Mode: logical
       -> Index Scan using users_pkey on users pu (cost=0.28..0.66 rows=1 width=24)
          Index Cond: ((id)::text = (parent_post.owned_by)::text)
    SubPlan 1
     -> Index Only Scan using post_tags_pkey on post_tags pt2 (cost=0.28..4.32 rows=2 width=6)
        Index Cond: (post_id = (p.id)::text)
||<

* listPostsByFollowees

FakebookのSNSとしての典型的なビューは、「自分がフォローしているユーザの投稿の一覧」を見ることである。これがログイン直後のデフォルトのビューでもある。このクエリが効率的に処理できるかどうかがSNSの性能を決めると言って良い。

基本戦略としては、表示件数が20件という定数であることを利用して計算量の削減を図る。全フォロイーの中から直近の投稿が新しい20人を選び、その20人の各々の最新の投稿20件を取り出すことで、最大400件のソートしかしないことが保証できる。実際のクエリは以下のものだ。

>|sql|
WITH
f AS (
  SELECT followee_id
  FROM user_follows
  WHERE follower_id = '9901000000000001'),
active AS (
  SELECT DISTINCT ON (p2.owned_by) p2.owned_by, p2.id AS last_id
  FROM posts p2
  WHERE p2.owned_by IN (SELECT followee_id FROM f)
  ORDER BY p2.owned_by, p2.id DESC),
top_followees AS (
  SELECT owned_by
  FROM active
  ORDER BY last_id DESC LIMIT 20),
cand AS (
  SELECT pid.id
  FROM top_followees tf
  JOIN LATERAL (
    SELECT p2.id
    FROM posts p2
    WHERE p2.owned_by = tf.owned_by
    ORDER BY p2.id DESC LIMIT 20) AS pid ON TRUE),
top AS (
  SELECT id
  FROM cand
  ORDER BY id DESC OFFSET 0 LIMIT 20)
SELECT
  p.id, p.snippet, p.owned_by, p.reply_to,
  p.allow_likes, p.allow_replies, p.created_at, p.updated_at,
  u.nickname AS owner_nickname, pu.nickname AS reply_to_owner_nickname,
  p.count_replies AS count_replies, p.count_likes AS count_likes,
  ARRAY(SELECT pt2.name FROM post_tags pt2
    WHERE pt2.post_id = p.id ORDER BY pt2.name) AS tags
FROM top t
JOIN posts p ON p.id = t.id
JOIN users u ON p.owned_by = u.id
LEFT JOIN posts parent_post ON p.reply_to = parent_post.id
LEFT JOIN users pu ON parent_post.owned_by = pu.id
ORDER BY t.id DESC;
||<

クエリが込み入っているので、部分ごとに解説しよう。

- フォローしているユーザのIDの一覧をfというビューとして作る。
- fの各々について最新の投稿IDを紐づけたactiveというビューを作る。
- activeの内容を投稿IDでソートして、最も最近に投稿をしたトップ20人のユーザIDの集合であるtop_followeesというビューを作る。
- top_followeesの各ユーザIDにJOIN LATERALして、各ユーザの最新投稿IDを20件ずつ取り出したcandというビューを作る。
- candの最大400件の投稿IDをソートして、最新20件に絞ったtopというビューを作る。
- topの各々のIDに対して、listPostsと同様に、各種属性を肉付けする。

これの計算量を考えよう。全ユーザ数をUと置き、全投稿数をPと置き、フォローしているユーザ数をFと置く。フォローしているユーザの一覧を引くのは、インデックスが利けば、O(log(U))だ。フォローしているユーザの各々の最新投稿を調べるのは、インデックスが利けば、O(F\*log(P))だ。F人から最新アクティブユーザ20人を選ぶのはtop-kヒープなので、O(F\*log(20)) で、20は定数なので、O(F)だ。最新アクティブユーザ20人の各々の最新投稿20件を取り出すと、400件が取れる。400件から20件を選ぶのもtop-kヒープなので、O(400\*log(20))で、400も20も定数なので、O(1)だ。そして20件の各々に肉付けする処理は、全てインデックスが利くなら、O(20\*log(P))で、20は定数なので、O(log(P))だ。つまり、UはPよりも少ないと仮定すると、全体の計算量の支配項はO(F\*log(P))ということになる。Pは莫大に大きくても大丈夫だし、Fはそこそこ大きくても大丈夫ということになる。ユーザ毎の最新投稿時刻をテーブルに分割して持っておくとO(F\*log(P))の項がO(F\*log(U))になって若干高速化するだろうが、そこまでする必要はないだろう。

あとは、各処理でちゃんとインデックスが効いているかどうかを確かめれば良い。上述のクエリをEXPLAINにかけてみると、以下の出力が得られる。全てがIndex Condの理想的な実行計画になっていることが確かめられた。

>||
Nested Loop Left Join (cost=9461.18..9727.60 rows=20 width=167)
 -> Nested Loop Left Join (cost=9460.90..9628.05 rows=20 width=145)
  -> Nested Loop (cost=9460.62..9619.31 rows=20 width=128)
    -> Nested Loop (cost=9460.35..9606.12 rows=20 width=121)
     -> Limit (cost=9460.06..9460.11 rows=20 width=17)
       -> Sort (cost=9460.06..9460.31 rows=100 width=17)
        Sort Key: p2_1.id DESC
        -> Nested Loop (cost=9369.04..9457.40 rows=100 width=17)
          -> Limit (cost=9368.75..9368.80 rows=20 width=34)
           -> Sort (cost=9368.75..9371.28 rows=1010 width=34)
             Sort Key: p2.id DESC
             -> Unique (cost=7.29..9341.88 rows=1010 width=34)
              -> Incremental Sort (cost=7.29..8918.21 rows=169466 width=34)
                Sort Key: p2.owned_by, p2.id DESC
                Presorted Key: p2.owned_by
                -> Nested Loop (cost=0.58..517.50 rows=169466 width=34)
                 -> Index Only Scan using user_follows_pkey on user_follows (cost=0.29..69.78 rows=1000 width=17)
                   Index Cond: (follower_id = '9901000000000001'::text)
                 -> Memoize (cost=0.29..0.58 rows=5 width=34)
                   Cache Key: user_follows.followee_id
                   Cache Mode: logical
                   -> Index Only Scan using idx_posts_owned_by_id on posts p2 (cost=0.28..0.57 rows=5 width=34)
                    Index Cond: (owned_by = (user_follows.followee_id)::text)
          -> Limit (cost=0.28..4.37 rows=5 width=17)
           -> Index Only Scan Backward using idx_posts_owned_by_id on posts p2_1 (cost=0.28..4.37 rows=5 width=17)
             Index Cond: (owned_by = (p2.owned_by)::text)
     -> Index Scan using posts_pkey on posts p (cost=0.28..7.30 rows=1 width=104)
       Index Cond: ((id)::text = (p2_1.id)::text)
    -> Index Scan using users_pkey on users u (cost=0.28..0.66 rows=1 width=24)
     Index Cond: ((id)::text = (p.owned_by)::text)
  -> Index Scan using posts_pkey on posts parent_post (cost=0.28..0.44 rows=1 width=34)
    Index Cond: ((id)::text = (p.reply_to)::text)
 -> Index Scan using users_pkey on users pu (cost=0.28..0.66 rows=1 width=24)
  Index Cond: ((id)::text = (parent_post.owned_by)::text)
 SubPlan 1
 -> Index Only Scan using post_tags_pkey on post_tags pt2 (cost=0.28..4.32 rows=2 width=6)
   Index Cond: (post_id = (p.id)::text)
||<

* listPostsLikedByUser

自分がイイネした投稿の一覧を得るには、以下のクエリが使われる。

>||
SELECT
  p.id, p.snippet, p.owned_by, p.reply_to,
  p.allow_likes, p.allow_replies, p.created_at, p.updated_at,
  u.nickname AS owner_nickname, pu.nickname AS reply_to_owner_nickname,
  p.count_replies AS count_replies, p.count_likes AS count_likes,
  ARRAY(SELECT pt.name FROM post_tags pt
    WHERE pt.post_id = p.id ORDER BY pt.name) AS tags
FROM post_likes pl
JOIN posts p ON pl.post_id = p.id
JOIN users u ON p.owned_by = u.id
LEFT JOIN posts pp ON p.reply_to = pp.id
LEFT JOIN users pu ON pp.owned_by = pu.id
WHERE pl.liked_by = '9901000000000001'
ORDER BY pl.created_at DESC OFFSET 0 LIMIT 20;
||<

liked_byでの絞り込みにインデックスが利きさえすれば、計算量はlistPostsと同じくO(log(P))で済むはずだ。あとは実行計画見れば、それが確認できる。

>||
Limit (cost=1.40..26.01 rows=1 width=181)
 -> Nested Loop Left Join (cost=1.40..26.01 rows=1 width=181)
    -> Nested Loop Left Join (cost=1.12..17.36 rows=1 width=157)
       -> Nested Loop (cost=0.84..16.96 rows=1 width=140)
          -> Nested Loop (cost=0.56..16.60 rows=1 width=131)
             -> Index Scan Backward using idx_post_likes_liked_by_created_at on post_likes pl (cost=0.28..8.30 rows=1 width=25)
                Index Cond: ((liked_by)::text = '9901000000000001'::text)
             -> Index Scan using posts_pkey on posts p (cost=0.28..8.30 rows=1 width=123)
                Index Cond: ((id)::text = (pl.post_id)::text)
          -> Index Scan using users_pkey on users u (cost=0.28..0.36 rows=1 width=26)
             Index Cond: ((id)::text = (p.owned_by)::text)
       -> Index Scan using posts_pkey on posts pp (cost=0.28..0.40 rows=1 width=34)
          Index Cond: ((id)::text = (p.reply_to)::text)
    -> Index Scan using users_pkey on users pu (cost=0.28..0.36 rows=1 width=26)
       Index Cond: ((id)::text = (pp.owned_by)::text)
    SubPlan 1
     -> Index Only Scan using post_tags_pkey on post_tags pt (cost=0.28..8.30 rows=1 width=5)
        Index Cond: (post_id = (p.id)::text)
||<

* listUsers

usersテーブルを操作するusersServiceという実装にも各種メソッドがあって、それぞれクエリを発行している。どれも軽い処理だが、ユーザの一覧を出すlistUsersだけは、注意を要する。例えば、ユーザのニックネームの前方一致条件で絞り込みを行いつつ、フォロイーもしくはフォロワーを優先して表示するという特殊機能がある。そのクエリは以下のものだ。

>|sql|
SELECT
  u.id, u.email, u.nickname, u.is_admin, u.snippet, u.avatar,
  u.ai_model, u.created_at, u.updated_at
FROM users u
LEFT JOIN user_follows f1 ON
  f1.follower_id = '9901000000000001' AND f1.followee_id = u.id
LEFT JOIN user_follows f2 ON
  f2.follower_id = u.id AND f2.followee_id = '9901000000000001'
WHERE LOWER(u.nickname) LIKE 'user2%'
ORDER BY
  (u.id = '9901000000000001') DESC,
  (f1.follower_id IS NOT NULL) DESC,
  (f2.follower_id IS NOT NULL) DESC,
  u.id ASC OFFSET 0 LIMIT 20;
||<

LIKE演算子による前方一致は、インデックスが利くので、絞り込みを効率的に行うことができる。また、フォロー関係の結合はビットマップインデックスとハッシュジョインで絞り、最後にソートで順位付けするため、ヒット件数が少なければ高速に動く。EXPLAIN文の結果は以下である。

>||
Limit (cost=494.27..494.32 rows=20 width=487)
 -> Sort (cost=494.27..494.55 rows=112 width=487)
    Sort Key: (((u.id)::text = '9901000000000001'::text)) DESC, ((f1.follower_id IS NOT NULL)) DESC, ((f2.follower_id IS NOT NULL)) DESC, u.id
    -> Hash Right Join (cost=360.65..491.29 rows=112 width=487)
       Hash Cond: ((f2.follower_id)::text = (u.id)::text)
       -> Bitmap Heap Scan on user_follows f2 (cost=20.04..145.53 rows=1000 width=17)
          Recheck Cond: ((followee_id)::text = '9901000000000001'::text)
          -> Bitmap Index Scan on idx_user_follows_followee_created_at (cost=0.00..19.79 rows=1000 width=0)
             Index Cond: ((followee_id)::text = '9901000000000001'::text)
       -> Hash (cost=339.21..339.21 rows=112 width=501)
          -> Hash Right Join (cost=267.08..339.21 rows=112 width=501)
             Hash Cond: ((f1.followee_id)::text = (u.id)::text)
             -> Index Only Scan using user_follows_pkey on user_follows f1 (cost=0.29..69.78 rows=1000 width=34)
                Index Cond: (follower_id = '9901000000000001'::text)
             -> Hash (cost=265.39..265.39 rows=112 width=484)
                -> Bitmap Heap Scan on users u (cost=9.40..265.39 rows=112 width=484)
                   Filter: (lower((nickname)::text) ~~ 'user2%'::text)
                   -> Bitmap Index Scan on idx_users_nickname_id (cost=0.00..9.38 rows=110 width=0)
                      Index Cond: ((lower((nickname)::text) ~>=~ 'user2'::text) AND (lower((nickname)::text) ~<~ 'user3'::text))
||<

さて、多くの処理がインデックスを使って行われているので、このクエリは一見速そうだ。実際、絞り込みの文字列が十分に長くてヒット件数が少ない場合には、最下層の文字列インデックスが効率的に働いて、少ない数のレコードを一瞬で返し、ハッシュマップを使って各々のレコードに効率的にスコアリングを施した上で、一瞬で処理を返してくれるだろう。問題は、絞り込みの文字列が短く、ヒット数が多い場合である。その場合、ヒットしたレコードの全てにスコアリングをしてからソートすることになるため、遅くなる。全ユーザ数をUとした場合、絞り込み文字列が1文字なら、Uの何割かがヒットしてしまうので、空間計算量はO(U)となる。それをtop-kヒープでソートする時間計算量は、kが20と小さいので、O(U)である。

なお、LIKE演算子による前方一致検索を効率的に動かすには、ちょっとしたコツがある。DBを作る際に、`POSTGRES_INITDB_ARGS: "--encoding=UTF8 --locale=C --lc-collate=C --lc-ctype=C"` などと指定して、コレーションを無効化することだ。Postgresのデフォルトでは文字列の比較を厳密なバイト比較ではなく、複数の文字を同一視するコレーションをした上で比較する。コレーションがあると、デフォルトのインデックスがLIKE演算子で使えない。その他の場面でも、コレーションのせいで効率が悪化することがありうるので、特にコレーションの要望がない限りは、コレーションは切っておいた方が無難だ。

コレーションを無効化したとしても、大文字と小文字の違いを無視するILIKE演算子には、デフォルトのインデックスは使えない。よって、nicknameのインデックスは `LOWER(nickname) text_pattern_ops` として小文字に正規化したものにしている。小文字に正規化したインデックスを十全に働かせるには、上述のクエリのように、クエリ内の条件も小文字に正規化する必要がある。そうでない場合、インデックスが使われない。

>||
# explain SELECT id, nickname FROM users WHERE LOWER(nickname) LIKE 'user2%' ORDER BY ID LIMIT 3;

Limit (cost=12.47..12.48 rows=3 width=24)
 -> Sort (cost=12.47..12.75 rows=112 width=24)
    Sort Key: id
    -> Index Only Scan using idx_users_nickname_id on users (cost=0.28..11.03 rows=112 width=24)
       Index Cond: (((lower((nickname)::text)) ~>=~ 'user2'::text) AND ((lower((nickname)::text)) ~<~ 'user3'::text))
       Filter: ((lower((nickname)::text)) ~~ 'user2%'::text)

# explain SELECT id, nickname FROM users WHERE nickname LIKE 'user2%' ORDER BY ID LIMIT 3;
Limit (cost=0.28..18.67 rows=3 width=24)
 -> Index Scan using users_pkey on users (cost=0.28..686.93 rows=112 width=24)
    Filter: ((nickname)::text ~~ 'user2%'::text)
||<

* listFriendsByNicknamePrefix

さて、上述のlistUsersメソッドは、それに与えられた外部仕様を満たすためには最善の実装ではあるが、SNSの実運用に供するには効率が悪すぎる。そこで、仕様を単純化したlistFriendsByNicknamePrefixという専用メソッドを設けた。ユーザリストはIDの昇順か降順で返すという原則を崩して、自分、フォロイー、その他の分類順で、各分類の中ではニックネームの辞書順にするという特殊仕様だ。あまりこういう専用メソッドを作りたくはないのだが、こればっかりはやらないと仕方がない。基本戦略としては、自分、フォロイー、その他大勢、を別々に処理して絞り込んでから、最後にUNION ALL結合する。具体的なクエリは以下のものだ。

>|sql|
WITH
  self AS (
    SELECT
      0 AS prio,
      u.id, lower(u.nickname) AS nkey
    FROM users u
    WHERE u.id = '9901000000000001' AND lower(u.nickname) LIKE 'user2%' ),
  followees AS (
    SELECT
      1 AS prio, u.id, lower(u.nickname) AS nkey
    FROM user_follows f
    JOIN users u ON u.id = f.followee_id
    WHERE f.follower_id = '9901000000000001' AND lower(u.nickname) LIKE 'user2%'
    ORDER BY lower(u.nickname), u.nickname, u.id LIMIT 20 ),
  others AS (
    SELECT
      3 AS prio, u.id, lower(u.nickname) AS nkey
    FROM users u
    WHERE lower(u.nickname) LIKE 'user2%'
    ORDER BY lower(u.nickname), u.nickname, u.id LIMIT 20 ),
  candidates AS (
    SELECT * FROM self
    UNION ALL
    SELECT * FROM followees
    UNION ALL
    SELECT * FROM others ),
  dedup AS (
    SELECT DISTINCT ON (id)
      id, prio, nkey
    FROM candidates
    ORDER BY id, prio ),
  page AS (
    SELECT
      id, prio, nkey
    FROM dedup
    ORDER BY prio, nkey, id OFFSET 0 LIMIT 20 )
SELECT
  u.id, u.email, u.nickname, u.is_admin, u.snippet, u.avatar,
  u.ai_model, u.created_at, u.updated_at
FROM page p
JOIN users u ON u.id = p.id
ORDER BY p.prio, p.nkey, u.id;
||<

selfとfolloweesとothersの3つの枝のそれぞれで最大20件のレコードだけを取り出していて、それぞれが20件だけのスキャンで早期終了することを企図している。取り出すレコードも優先度とIDとニックネームだけの最低限に絞っている。そして、dedup処理では、id, prio, nkeyでソートしてから重複IDを除いていて、prioの最小値が採択されている。最後に最終順序でソートした20件だけに他の属性を肉付けして返している。

これの計算量を考えよう。全ユーザ数をUと置き、フォロイー数をFと置く。自分を調べるのは、O(log(U))だ。フォロイーの一覧を引くのは、O(log(U\*F)+F)だ。検索文字列が短い場合、ほとんど絞り込みが働かないので、フォロイー全員のニックネームを調べることになる。よって、その計算量はO(F\*log(U))だ。フォロイーのヒット全てを並び替える計算量はO(F\*log(F))だ。全員を調べる枝では、検索文字列が短い場合でも、確実に早期終了するので、計算量はO(log(U))だ。つまり、FはUより十分に小さいと仮定すると、支配項はO(F\*log(U))ということになる。EXPLAIN文の結果は以下である。全ての枝（Subquery）でIndex Condが働いていて、早期終了するので、効率は最善だ。フォロイーの枝でフォロイー毎にレコードを調べているのもわかる。

>||
Nested Loop (cost=114.05..247.88 rows=20 width=520)
 -> Limit (cost=113.77..113.82 rows=20 width=53)
  -> Sort (cost=113.77..113.87 rows=41 width=53)
    Sort Key: "*SELECT* 1".prio, "*SELECT* 1".nkey, "*SELECT* 1".id
    -> Unique (cost=112.48..112.68 rows=41 width=53)
     -> Sort (cost=112.48..112.58 rows=41 width=53)
       Sort Key: "*SELECT* 1".id, "*SELECT* 1".prio
       -> Append (cost=0.28..111.38 rows=41 width=53)
        -> Subquery Scan on "*SELECT* 1" (cost=0.28..8.31 rows=1 width=53)
          -> Index Scan using users_pkey on users u_1 (cost=0.28..8.30 rows=1 width=53)
           Index Cond: ((id)::text = '9901000000000001'::text)
           Filter: (lower((nickname)::text) ~~ 'user2%'::text)
        -> Subquery Scan on followees (cost=88.08..88.33 rows=20 width=53)
          -> Limit (cost=88.08..88.13 rows=20 width=60)
           -> Sort (cost=88.08..88.35 rows=111 width=60)
             Sort Key: (lower((u_2.nickname)::text)), u_2.nickname, u_2.id
             -> Hash Join (cost=12.71..85.12 rows=111 width=60)
              Hash Cond: ((f.followee_id)::text = (u_2.id)::text)
              -> Index Only Scan using user_follows_pkey on user_follows f (cost=0.29..69.78 rows=1000 width=17)
                Index Cond: (follower_id = '9901000000000001'::text)
              -> Hash (cost=11.03..11.03 rows=112 width=24)
                -> Index Only Scan using idx_users_nickname_id on users u_2 (cost=0.28..11.03 rows=112 width=24)
                 Index Cond: (((lower((nickname)::text)) ~>=~ 'user2'::text) AND ((lower((nickname)::text)) ~<~ 'user3'::text))
                 Filter: ((lower((nickname)::text)) ~~ 'user2%'::text)
        -> Subquery Scan on others (cost=14.29..14.54 rows=20 width=53)
          -> Limit (cost=14.29..14.34 rows=20 width=60)
           -> Sort (cost=14.29..14.57 rows=112 width=60)
             Sort Key: (lower((u_3.nickname)::text)), u_3.nickname, u_3.id
             -> Index Only Scan using idx_users_nickname_id on users u_3 (cost=0.28..11.30 rows=112 width=60)
              Index Cond: (((lower((nickname)::text)) ~>=~ 'user2'::text) AND ((lower((nickname)::text)) ~<~ 'user3'::text))
              Filter: ((lower((nickname)::text)) ~~ 'user2%'::text)
 -> Index Scan using users_pkey on users u (cost=0.28..6.69 rows=1 width=484)
  Index Cond: ((id)::text = ("*SELECT* 1".id)::text)
||<

* 総評

ここまで見てきたように、記事IDやユーザIDのリストを取得するための検索操作は全てインデックス上で行えるように、スキーマとクエリを設計している。各々のインデックスは小さいので、大部分がメモリ上にキャッシュされて、高速にランダムアクセスできる。よって、Fakebookの主要クエリは、全てスケールするものになっていると言える。

全体の最新投稿を一覧で使うlistPostsの計算量はO(log(P))だ。自分がフォローしているユーザの最新投稿を一覧で使うlistPostsByFolloweesの計算量はO(F\*log(P))で済んでいる。イイネした投稿の一覧で使うlistPostsLikedByUserの計算量はO(log(P))だ。その他、全ての投稿一覧はO(log(P))以下の計算量に留めている。ユーザ一覧に関しても同様で、全文検索以外で最も重いlistFriendsByNicknamePrefixの計算量もO(F\*log(U))に留めている。

最も重いlistPostsByFolloweesとlistFriendsByNicknamePrefixの計算量はフォロイー数Fに比例する。したがって、フォロイー数を定数項にするために、上限値を決める必要がある。現実的には100人以上フォローしても使い勝手が悪くなるだけなので、200人くらいを上限値にすれば問題ないだろう。Fが定数であれば、計算量はO(log(P))とO(log(U))と表せるわけで、だれがどう見ても健全なシステムになる。

投稿記事の本文やユーザ自己紹介の本文などのでかいデータを取得する操作も、スケーラビリティの制限要因になる。主キーに紐づいたテーブル本体のレコードを読み出すという操作は、レコード数Nに対してO(log(N))の計算量に過ぎない。しかし、データの規模が大きいと遅くなる。メモリ上のキャッシュに乗り切らないので、毎回のアクセスでストレージにアクセスするからだ。HDDであればシークタイムも加算される。読み出しのデータが大きいと、ストレージとメモリの間のデータ転送量が増えることでも遅くなる。postsとusersテーブルに本文を入れずにスニペットだけを入れるのは、この問題に対する緩和策だ。

* 余談

スニペットをDBに保存するということは、「どう表示するか」というフロントエンド側のプレゼンテーションの知識をバックエンド側で持つことを意味するため、責任分割の観点では気持ち悪い。スニペットの形式や文字数制限を変えた際にDBのレコードを入れ直さなきゃならないのも嫌だ。しかし、その気持ち悪さを飲んでもやらねばならない。

投稿記事やユーザ自己紹介の本文を分離するという手法は、いわゆる垂直分散の一種である。属性データの特性に合わせて管理方法を分割する手法とも言える。本文だけDBサーバを分けてもいいし、列指向DBに入れてもいいし、S3に入れてクライアントに直接取得させたっていい。古い記事の本文は圧縮した上でアーカイブ用のストレージに入れてもいい。post_likesやuser_followsといったテーブルを別サーバで管理するのも良いだろう。

以上のことを鑑みると、リソースのリストを取得する処理は、常に二段構えで考えるべきだ。条件に該当するIDのリストを生成する段と、そのIDに紐づけて属性を収集する段だ。RDB1台運用だとその2段が一発のクエリでできるが、それでもサブクエリを使って敢えて2段に分けて書くのも良い考えだ。以下の二つのクエリは等価で、後者の方が若干遅いかもしれないが、いずれ垂直分散する際は、後者の書き方をしておく方がバグりにくい。

>|sql|
SELECT id, nickname, introduction
FROM USERS WHERE id > '0001000000000002'
ORDER BY id LIMIT 10;

WITH cand_ids AS (
  SELECT id FROM users
  WHERE id > '0001000000000002'
  ORDER BY id LIMIT 10
)
SELECT u.id, u.nickname, u.introduction
FROM users AS u
JOIN cand_ids AS c ON u.id = c.id
ORDER BY c.id;
||<

なお、PostgreSQLでは、TOASTという機能があり、2KB以上の大きい列データを暗黙的に圧縮したり別テーブルに移動したりして、個々のレコードが単一ページに収まるように努力してくれる。よって、明示的に分割しなくても、ある程度の最適化は勝手になされる。しかし、それでもなお、大きさや参照頻度が異なるデータは明示的に分割した方が良い。今回の例では、スニペットさえあればリスト取得時には本文を一切参照する必要がないので、短くても長くても別テーブルにした方が、主テーブルのページ読み出し量が少なくて済む。

[zu]

指定した列の短いデータも強制的にTOASTしてくれれば、わざわざテーブル分割しなくても済むのにと思ったが、そのような指定はできない。また、テーブル分割した先では、TOASTしなくてもよいとも思ったが、そのような指定もできない。TOASTの本来の目的は参照局所性の向上ではなく、主テーブルの各レコードのサイズをページサイズ（8KB）以下に抑えることだからだ。なお、TOASTは圧縮もしてくれるが、そのデフォルトの圧縮方式はpglz（LZ77）で、遅い割には圧縮率があまり良くない。なので、今回はDB全体の圧縮設定をLZ4に変更している。LZ4は無圧縮に近い速度で動く割には、自然言語の文字列を半分くらいに圧縮する能力があるので、LZ4に変更する利点は大きい。

垂直分割をしても処理しきれなくなってきたら、いよいよ水平分割をすることになる。ユーザIDを使ってパーティショニングを行うのが率直な方法だろう。ハッシュ値などで機械的に割り振っても良いが、各ユーザがどのパーティションに居るのかを管理するuser_partitionsテーブルを作るか、それに相当するKVSを運用するのが率直だ。usersテーブルを引く時はユーザIDでパーティションを特定してからそのDBサーバにアクセスし、postsテーブルを引く時は著者のユーザIDでパーティションを特定してからそのDBサーバにアクセスする。フォロー関係は、フォロー元のユーザとフォロー先のユーザのDBに二重化して持たせれば良い。垂直分割を経ているならば、もはやJOINするクエリは少なくなっていて、IDのリストを取り出してから別のDBにアクセスする作法は確立しているはずだ。あとはそのアクセス先を個々のIDに紐づいたパーティションにするだけだ。ユーザに紐づいた一連のデータをパーティション間で移動するユーティリティさえ書いておけば、運用はそんなに難しくない。

規模が大きくなると、投稿一覧の「All」のビューがほとんど意味をなさなくなってくる。見知らぬ人の投稿を全て見る奴は居ない。となると、「Pickup」とか「Topics」とかいう位置づけのビューを代わりに置くことになるだろう。最近の投稿だけを集めた小さいデータベースを作っておいて、質が高いものや個々のユーザの興味に近そうなものをバッチ処理で計算して、それを提示するのだ。

記事本文やユーザプロファイル本文を対象とする全文検索は、DB本体で頑張るよりは、別システムに移譲した方がよい。別ホストで運用し、そこにバッチ処理で定期的にデータを流し込めば良い。検索エンジンが重くなっても主たる機能の運用に影響がないというのは実運用上で非常に重要だ。

* おわりに

ここまでいろいろ述べたが、Fakebookの現状の目標は、スケーラビリティを追求することではない。SNSの基本機能を率直に実装した、シンプルで典型的で教科書的なシステムを作ることだ。規模Nに対して各種クエリの時間計算量がN未満であることが保証できていれば良い。少なくとも開発の初期段階では、見通しがよく開発と保守がしやすいスキーマを選択すべきで、現状のスキーマはそれに叶うものになっている。時期尚早の最適化をして、人気が出る前に開発が頓挫するというのでは意味がないので、シンプルな構成から始めるというのも重要だ。

次回以降は、メディアストレージの実装、通知機能、UIの詳細などについて解説していく。
