id: 0002000000000012
ownedBy: 0001000000000002
allowLikes: false
allowReplies: false
tags: stgy-help
content:<<____EOF____
# STGYのインストール

本記事では、STGYのシステム全体を、開発環境とデモ運用環境の双方にインストールする方法について説明する。Dockerを使った運用と実サービスを使った運用の双方についても説明する。

## Mac OS上での開発環境の構築

STGYの開発作業はDockerが動く環境であればどこでもできるが、ここではMac OSでの環境構築方法について述べる。Linuxについてはデモ環境の構築方法と一緒に後述する。Mac上では、作業環境は自宅等のホームネットワーク環境を想定し、外部からの接続を受け付けることは想定しない。Dockerを使って各種の依存サービスを立てた上で、自ら開発するSTGYのバックエンドサービスとフロントエンドサービスをローカルホストで動かしながら開発を進める。検証時のために、バックエンドサービスとフロントエンドサービスも含めて全てDockerで動くようにもする。

まずは、Homebrewを入れる。カスタマイズ性の高いMacPortsとかよりも、通り一遍で再現性の高い手順となるHomebrewの方が管理しやすい。

```
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
echo 'eval "$(/opt/homebrew/bin/brew shellenv)"' >> ~/.zprofile
eval "$(/opt/homebrew/bin/brew shellenv)"
```

Homebrewで、その他の必要パッケージを入れる。Docker VMであるColima、Dockerクライアント、composeプラグイン、Node.js、Git、GitHub CLIである。

```
brew install colima docker docker-compose node git gh
```

Colimaを起動する。初回の起動ではリソースの使用量をオプションで指定する。

```
colima start --cpu 4 --memory 8 --disk 100
```

DockerクライアントがColimaを使うように設定する。

```
docker context use colima
```

~/.docker/config.jsonに以下のような記述をして、ColimaとComposeプラグインを利用可能にする。Colima等の既存の設定があればそのまま残す。

```
{
	"auths": {},
	"currentContext": "colima",
  "cliPluginsExtraDirs": ["/opt/homebrew/lib/docker/cli-plugins"]
}
```

Dockerクライアントの動作確認をする。それぞれ、「Docker Compose version 2.39.3」的な文字列と「Hello from Docker!」が表示されれば成功。

```
docker compose version
docker run --rm hello-world
```

Node.jsの動作確認をする。それぞれ、「v24.4.0」と「11.4.2」的な文字列が表示されれば成功。

```
node -v
npm -v
```

GitHubにログインする。アクセスキーを聞かれるので、事前にGitHub上でアクセスキーを作っておくこと。

```
gh auth login
```

開発作業用のディレクトリを作り、stgyのリポジトリのクローンを作成する。以後、stgyディレクトリで作業を行う。

```
mkdir ~/dev
cd ~/dev
git clone git@github.com:estraier/stgy.git
cd stgy
```

## リポジトリ構成

STGYの関連パッケージは全て単一のリポジトリに収められている。いわゆるmonorepo構成である。主要なディレクトリ構造とファイルを以下に示す。

- package.json : NPMでパッケージ管理をするための設定ファイル
- package-lock.json : 依存パッケージのバージョンを固定するための設定ファイル
- docker-compose.yml : 依存サービスをDockerで管理するための設定ファイル
- docker-compose.vps.yml : VPSのデモ環境用に上記設定を上書きするためのファイル
- env-dev.txt : docker composeや他のスクリプトが読み込む環境設定ファイル
- env-vps.txt : VPSのデモ環境用の環境変数設定ファイル
- Caddyfile : リバースプロクシCaddyの設定ファイル
- Caddyfile.vps : VPSのデモ環境用で使うCaddyの設定ファイル
- packages/ : 独自の依存パッケージ群のディレクトリ
- backend/ : バックエンドサービスのソースコードや設定ファイル一式のディレクトリ
- frontend/ : フロントエンドサービスのソースコードや設定ファイル一式のディレクトリ
- scripts/ : 管理用の便利スクリプト一式のディレクトリ
- tests/ : テスト用のコードやファイル一式のディレクトリ
- postgres/ : PostgreSQLの設定一式のディレクトリ
- minio/ : MinIOの設定一式のディレクトリ
- seeder/ : 初期登録データ一式のディレクトリ

パッケージ管理はNPMで行っており、その設定はpackage.jsonに書いてある。Dockerの管理はそこにあるスクリプトコマンドを叩いて行う。ワークスペース構成を取っていて、packages/markdownとbackendとfrontendの下にあるpackage.jsonはその管理下にある。それぞれのサブパッケージには、以下の共通したファイルやディレクトリが格納されている。

- package.json : NPMでパッケージ管理をするための設定ファイル
- tsconfig.json : TypeScriptのビルド設定ファイル
- tsconfig.lint.json : eslintが使うビルド設定ファイル
- eslint.config.mjs : eslintによるコード解析の設定ファイル
- jest.config.js : jestによるユニットテストの設定ファイル
- src/ : ソースコード一式

依存パッケージのインストールはプロジェクトルート直下に作られるnode_modulesディレクトリに格納され、それらのバージョンはpackage-lock.jsonで固定される。以下のコマンドで依存関係を処理する。

- npm ci : 固定されたバージョンの依存パッケージをインストールする
- npm install : package.jsonの記述に基づき、新しいバージョンの依存パッケージをインストールする
- npm run clean : 依存パッケージを消す

backendとfrontendにはDockerfileがあり、それぞれのサービスのDockerインスタンスの設定が書いてある。それ以外の依存サービスの設定はdocker-compose.ymlに直接書いてある。docker composeは.envファイルから環境変数を読み込むが、それはリポジトリには含まれない。env-dev.txtかenv-vps.txtを.envにコピーするかシンボリックリンクを張るかしてから、それを環境に合わせて編集して使う。.envにはパスワードなどの秘密情報が書かれるので、Gitの管理対象にすべきではない。

scriptsの下には、システムの管理に必要なスクリプトが入っている。多くのものはnpmを介して起動される。.envの環境変数から設定を読み込むので、.envを事前に作っておく必要がある。

- reset-data.sh : PostgreSQLのデータベースを初期化し、seederの初期データを投入する
- reset-minio-data.sh : MinIOのデータベースを初期化する
- reset-cache.sh : Redisのキャッシュデータを初期化する
- edit_users.py : ユーザを作成または更新する
- edit_posts.py : 投稿を作成または更新する
- user_actions.py : 個々のユーザでログインしてイイネやフォローやブロックを行う
- make_volume_test.py : 検証用に大量のユーザと投稿を作成する
- run-local-backend.sh : バックエンドサービスをローカルホスト上で起動する
- run-local-frontend.sh : フロントエンドサービスをローカルホスト上で起動する
- run-databaseUtil.sh : データベース管理用のユーティリティ
- run-storageUtil.sh : メディアストレージ管理用のユーティリティ

postgresの下にはデータベースのスキーマ定義を行うSQLファイルが置いてある。minioの下にはバケットの初期設定を行うスクリプトが置いてある。

## 開発環境でのサービスの起動と終了

Macの開発環境においては、以下のコマンドでDockerホストVNの起動と終了を行う。

- colima start
  - Colimaを起動
- colima stop
  - Colimaを停止する
- colima restart
  - Colimaを再起動する

以下のコマンドでDocker上のサービスの起動と終了を行う。

- npm run docker:init
  - ホスト全体を初期化。他プロジェクトも含めてすべてのコンテナとイメージとボリュームを強制削除する。データも消える。
- npm run docker:reset
  - Dockerイメージを削除して再作成する。
- npm run docker:build
  - Dockerイメージを作成する。
- npm run docker:destroy
  - Dockerイメージを削除する。
- npm run docker:create
  - Dockerコンテナを作成する。必要ならネットワークやボリュームも作成。イメージのpullも行う。
- npm run docker:remove
  - Dockerコンテナを削除する。
- npm run docker:up
  - Dockerイメージの作成、Dockerコンテナの作成、Dockerコンテナの起動を一気に行う。
- npm run docker:down
  - Dockerコンテナの停止と削除を一気に行う。
- npm run docker:start
  - Dockerコンテナを起動する。
- npm run docker:stop
  - Dockerコンテナを停止する。

Docker関係のコマンドを利用目的別に整理する。

- 最も簡単に全サービスの起動と終了を行う。
  - npm run docker:up
  - npm run docker:stop
- まっさらな状態から逐次的にサービス起動状態までたどり着く
  - npm run docker:build
  - npm run docker:create
  - npm run docker:start
- サービス起動状態から逐次的にまっさらな状態に戻す。
  - npm run docker:stop
  - npm run docker:remove
  - npm run docker:destroy
- ビルド設定やTypeScriptコードの変更を強制反映してサービスを再起動する。
  - npm run docker:reset
  - npm run docker:start
- ビルド設定やTypeScriptコードの変更を差分反映してサービスを再起動する。
  - npm run docker:up
- Docker環境全体とデータを完全初期化する。ストレージ逼迫の場合もこれを使う。
  - npm run docker:init

開発中には、backendとfrontendはローカルホストで起動し、その他の依存サービスのみをDockerで起動するのが楽である。以下の手順で行う。

- npm ci
  - ローカル環境に外部依存パッケージをインストールする。
- npm run packages:build
  - ローカル環境で内部依存パッケージをビルドして準備する。
- npm run docker:start-dev
  - backendとfrontend以外の依存サービスのDockerコンテナを起動する。
  - 止める時はnpm run docker:stopを実行する。
- ./scripts/run-local-backend.sh
  - backendサービスと各種ワーカをローカルホストで起動する。
  - 止める時はCtrl-Cで落とす。
- ./scripts/run-local-backend.sh
  - frontendサービスをローカルホストで起動する。
  - 止める時はCtrl-Cで落とす。
- npm run reset-data
  - DBとオブジェクトストレージを初期化して、初期データを投入する。
- npm run reset-data-test
  - DBとオブジェクトストレージを初期化して、性能テスト用の大量のデータを投入する。
- npm run reset-cache
  - Redisのキャッシュを初期化する。

バックエンドやフロントエンドのTypeScriptコードを変更すると、それぞれの起動中のサービスは勝手に再起動して変更を取り込む。ただし、tscやlintのチェックが甘いので、そのままだとDockerイメージにした時に動く保証がない。よって、以下のコマンド群で品質管理をする。frontendやbackendの中で実行しても良い。

- npm run test
  - *.test.tsに書かれたユニットテストを実行する。
  - backendやfrontendの中でnpm run testとしてもよい。
- npm run lint
  - eslintで静的なコードの検証を行う。
- npm run build
  - tscの厳格なルールで本番用にビルドする。
- npm run fmt
  - prettierでコードを整形する。

## Linux上での開発環境の構築

Linux上で本システムの稼働と開発を行うための環境設定の手順を記す。まずは、Macの時と同様に、Dockerを使ってサービスを立ち上げる方法を示す。バックエンドとフロントエンドをローカルで動かすことも当然できる。データセンター等の環境を想定し、インターネットからの接続を受け付ける。ドメインを取得し、VPSのホストが利用できることを前提とする。ここでは、stgy.jpというドメインを取得し、VPS上のUbuntu Linux環境の上でシステムを構築する。IPアドレスは153.127.47.206が割り振られている。

事前にドメイン取得サービスのDNS設定で、該当ホストのAレコードを設定する。主たるドメインと、画像配信やその他のサブドメインを同じIDアドレスで登録する

- サブドメイン=(空文字列)、種別=A、値=153.127.47.206
- サブドメイン=s3、種別=A、値=153.127.47.206
- サブドメイン=s3-console、種別=A、値=153.127.47.206
- サブドメイン=www、種別=A、値=153.127.47.206

上記設定が伝搬していることを確認する。「Name: stgy.jp Address: 153.127.47.206」的な文字列が表示されれば成功。

```
nslookup stgy.jp
```

VPSサービスのコントロールパネルで、Ubuntuの最新のLTS版をインストールし、コンソールからログインして初期設定の作業を行う。初期ユーザ「ubuntu」でログインするが、それはスーパーユーザではないので、sudoして管理作業を行う。インストール後の初期設定が終わったら自分のユーザを作り、以後はそのユーザからsudoして作業を行う。

- ソフトウェアリストの更新: sudo apt update
- ソフトウェアの更新: sudo apt upgrade
- ロケールのインストールと有効化:
  - sudo apt install locales
  - vi /etc/locale.genを開いて必要なロケール（en_US.UTF-8 UTF-8とja_JP.UTF-8 UTF-8）を戻す
  - sudo locale-gen
- ホスト名の設定: sudo hostnamectl set-hostname setagaya
- 通常ユーザ作成: adduser mikio
- sudo権限付与: sudo gpasswd -a mikio sudo
- 再起動: sudo shutdown -r now

ファイアウォールを設定する。SSHの22、HTTPSの443、HTTPの80だけを開ける。

- sudo ufw default deny incoming
- sudo ufw default allow outgoing
- sudo ufw allow ssh
- sudo ufw allow https
- sudo ufw allow http
- sudo ufw enable
- sudo ufw status

自分のユーザでログインして、環境設定を行う。

- SSHの鍵設定:
  - .ssh/id_rsaと.ssh/id_rsa.pubと.ssh/authorized_keysを既存環境からコピー。
  - パーミッション設定: chmod 600 .ssh ; chmod 755 .ssh/*
- 最低限の環境設定
  - .bash_profileと.bashrcを既存環境からコピー
- エディタの設定
  - sudo apt install emacs
  - .emacsを既存環境からコピー
  - なぜかemacsと一緒にに入るpostfixの削除: sudo apt purge postfix

Certbotを入れる。

```
sudo apt update
sudo apt install -y snapd
sudo snap install core; sudo snap refresh core
sudo snap install --classic certbot
sudo ln -s /snap/bin/certbot /usr/bin/certbot
```

Docker関連ツールを入れる。標準ではaptがDockerの公式リポジトリを見ないので、設定を加える必要がある。

- sudo install -m 0755 -d /etc/apt/keyrings
- curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
- echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list >/dev/null
- sudo apt update
- sudo apt install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin

Dockerサービスを有効化する。また、dockerグループに自分を入れて利用可能にする。

- sudo systemctl enable --now docker
- sudo usermod -aG docker "$USER"
- newgrp docker

Dockerクライアントの動作確認をする。それぞれ、「Docker version 28.4.0」「Docker Compose version 2.39.3」的な文字列と「Hello from Docker!」が表示されれば成功。

```
docker --version
docker compose version
docker run --rm hello-world
```

Node.jsとnpmをインストールする。Ubuntuのデフォルトは古いので、Node 22系に手動更新する。

- curl -fsSL https://deb.nodesource.com/setup_22.x | sudo -E bash -
- sudo apt install nodejs npm

Node.jsの動作確認をする。それぞれ、「v22.19.0」と「10.9.3」的な文字列が表示されれば成功。

```
node -v
npm -v
```

GitとGitHub CLIをインストールする。

- sudo apt install git gh

GitHubにログインする。アクセスキーを聞かれるので、事前にGitHub上でアクセスキーを作っておくこと。

```
gh auth login
```

開発作業用のディレクトリを作り、stgyのリポジトリのクローンを作成する。以後、stgyディレクトリで作業を行う。

```
mkdir ~/dev
cd ~/dev
git clone git@github.com:estraier/stgy.git
cd stgy
```



* 運用環境の選択

AWS上でRDSとS3を使って構築できるシステムアーキテクチャになっているのだが、多数のマネージドサービスを使うと、デモで使うにはちょっとランニングコストが高くなりすぎる。デプロイも面倒くさい。なので、しばらくは1台構成のVPSで動かすことにした。さくらVPSの4GBプランなら月4000円以下で運用できるし、ストレージが400GBまで使えるので、ユーザ数がかなり増えても大丈夫だろう。何より、固定額なのが安心だ。1円の収益にもなっていない趣味のサービスが物量攻撃されて何十万円も払う羽目になったら心がくじけてしまうだろう。デモ運用しているうちは、従量課金で際限なく金がかかるよりは、サービスが落ちる方がマシだ。

VPSで依存サービスを自前で運用するとして、それらを実サービスとして動かすか、Dockerコンテナとして動かすかは、選択できる。実サービスとして動かす方法だと、性能上は最善で、ホストが単一なので手動での設定作業も楽だが、自動化しづらいので何度もやるのは厳しい。Dockerコンテナとして動かす方法だと、最初のコンテナの設定はややこしいが、一度やっておけば自動デプロイが簡単にできるようになる。Docker上で動かすとCPU効率とメモリ効率とI/O効率がほんの少し落ちる可能性はあるが、LinuxのDocker層のオーバーヘッドはほぼ無視できる程度に小さいので、性能に関しては気にする必要はない。よって、とりあえずはDockerで動くようにしよう。開発環境とほぼ同じ設定で、VPS上でDockerを動かして、そこにデータベースもオブジェクトストレージもバックエンドサーバもフロントエンドサーバも乗せてしまう。



## インストール






Next: [STGYのデータベース](/posts/0002000000000013)
____EOF____
