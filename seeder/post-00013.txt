id: 0002000000000013
ownedBy: 0001000000000002
allowLikes: false
allowReplies: false
tags: fakebook-help
content:<<____EOF____
# Fakebookの主要クエリ分析

本記事では、Fakebookの運用上でデータベースに発行されるクエリについて分析する。SQLの具体例を示し、その計算量を解析し、実際の実行計画を見て確認する。

## listPostsLite

全ての投稿の中から最新20件を取り出す処理を考える。バックエンドのpostsService.listPostsLiteというメソッドでそれは実装されている。デフォルトでは返信以外の投稿を一覧するため、reply_toがNULLであるという条件をつける。実際のクエリは以下のものだ。

```sql:small
SELECT
  p.id, p.owned_by, p.reply_to,
  p.allow_likes, p.allow_replies, p.created_at, p.updated_at
FROM posts p
WHERE reply_to IS NULL
ORDER BY p.id DESC OFFSET 0 LIMIT 20;
```

postsテーブルには、reply_toがNULLのレコードだけを対象としたIDの部分インデックスが設けられているため、そのインデックスを引くだけで処理が完了する。全ての投稿数をPと置くと、計算量はO(log(P))で済む。これは、Pが莫大になっても性能に問題が出ないことを意味している。

PostgreSQLでは、クエリごとの実行計画をEXPLAIN文で調べることができる。以下の出力が得られる。インデックスを使って済むと言っている。推定3021件のレコードを持つインデックスを逆向きに操作して、20件がヒットした段階で処理を打ち切ることが示唆されている。つまりめちゃくちゃ効率的に動くということだ。

```:xsmall
Limit (cost=0.28..3.56 rows=20 width=96)
 -> Index Scan Backward using idx_posts_root_id on posts p (cost=0.28..496.23 rows=3021 width=96)
```

## listPosts

実運用上は、各投稿の著者のユーザIDを名前に解決したり、各投稿につけられたタグ情報を結果に含めるために、別のテーブルをJOINすることになる。それを実装しているのが、listPostsメソッドだ。reply_toがNULLであるという条件をつけると、実際のクエリは以下のものになる。

```sql:small
SELECT
  p.id, p.snippet, p.owned_by, p.reply_to,
  p.allow_likes, p.allow_replies, p.created_at, p.updated_at,
  u.nickname AS owner_nickname, pu.nickname AS reply_to_owner_nickname,
  p.count_replies AS count_replies, p.count_likes AS count_likes,
  ARRAY(SELECT pt2.name FROM post_tags pt2
    WHERE pt2.post_id = p.id ORDER BY pt2.name) AS tags
FROM posts p
JOIN users u ON p.owned_by = u.id
LEFT JOIN posts parent_post ON p.reply_to = parent_post.id
LEFT JOIN users pu ON parent_post.owned_by = pu.id
WHERE p.reply_to IS NULL
ORDER BY p.id DESC OFFSET 0 LIMIT 20;
```

listPostsLiteの場合と同様にインデックスが使われて、結果を返却するはずだ。その過程で、post_tagsテーブルとusersテーブルを結合している。タグに関しては返却の各行に対応して投稿IDが一致するタグをサブクエリで調べて取得して埋め込んでいる。ユーザ名に関しては、owned_byのIDをユーザ名に解決するためと、reply_toの投稿のowned_byのIDをユーザ名に解決するために、2回に分けてJOINしている。

これの計算量を考えよう。全ユーザ数をUと置き、全投稿数をPと置く。タグの数はおそらく投稿数の1%くらいの数になるだろうが、Pに比例するのでPとして扱う。まず、該当の投稿のリストを得るのに、インデックスが利けば、O(log(P))+O(20)の計算量がかかる。20は定数なので消えて、O(log(P))になる。そして、ヒットした20件の各々に対し、タグとユーザ名を解決する。インデックスが利けば、タグ取得はO(20\*log(P))で、ユーザ名取得はO(20\*log(U))だ。20は定数なので消えて、O(log(P))とO(log(U))になる。UはPよりも十分に少ないと仮定すると、全体の支配項はO(log(P))ということになる。つまり、計算量はlistPostsの時と同じである。

EXPLAIN文で実行計画を調べると、以下の出力が得られる。投稿でヒットしたレコードの各々に対して処理を行うNested Loopがあり、そこでJOINの処理を行っている。結合先のテーブルからデータを取り出すにあたっては全てインデックスが使われ、一部はキャッシュも使われていて、DB本体のシーケンシャルスキャン（Seq Scan）やインデックスのシーケンシャルスキャン（Filter）がひとつもなく、全てがインデックスの条件付き絞り込み（Index Cond）の理想的な処理になっていることがわかる。

```:xsmall
Limit (cost=1.14..106.13 rows=20 width=150)
 -> Nested Loop Left Join (cost=1.14..15858.95 rows=3021 width=150)
    -> Nested Loop Left Join (cost=0.86..2073.97 rows=3021 width=128)
       -> Nested Loop (cost=0.57..1474.58 rows=3021 width=111)
          -> Index Scan Backward using idx_posts_root_id on posts p (cost=0.28..496.23 rows=3021 width=104)
          -> Memoize (cost=0.29..0.91 rows=1 width=24)
             Cache Key: p.owned_by
             Cache Mode: logical
             -> Index Scan using users_pkey on users u (cost=0.28..0.90 rows=1 width=24)
                Index Cond: ((id)::text = (p.owned_by)::text)
       -> Memoize (cost=0.29..0.54 rows=1 width=34)
          Cache Key: p.reply_to
          Cache Mode: logical
          -> Index Scan using posts_pkey on posts parent_post (cost=0.28..0.53 rows=1 width=34)
             Index Cond: ((id)::text = (p.reply_to)::text)
    -> Memoize (cost=0.29..0.67 rows=1 width=24)
       Cache Key: parent_post.owned_by
       Cache Mode: logical
       -> Index Scan using users_pkey on users pu (cost=0.28..0.66 rows=1 width=24)
          Index Cond: ((id)::text = (parent_post.owned_by)::text)
    SubPlan 1
     -> Index Only Scan using post_tags_pkey on post_tags pt2 (cost=0.28..4.32 rows=2 width=6)
        Index Cond: (post_id = (p.id)::text)
```

## listPostsByFollowees

FakebookのSNSとしての典型的なビューは、「自分がフォローしているユーザの投稿の一覧」を見ることである。これがログイン直後のデフォルトのビューでもある。このクエリが効率的に処理できるかどうかがSNSの性能を決めると言って良い。

基本戦略としては、表示件数が20件という定数であることを利用して計算量の削減を図る。全フォロイーの中から直近の投稿が新しい20人を選び、その20人の各々の最新の投稿20件を取り出すことで、最大400件のソートしかしないことが保証できる。実際のクエリは以下のものだ。

```sql:small
WITH
f AS (
  SELECT followee_id
  FROM user_follows
  WHERE follower_id = '9901000000000001'),
active AS (
  SELECT DISTINCT ON (p2.owned_by) p2.owned_by, p2.id AS last_id
  FROM posts p2
  WHERE p2.owned_by IN (SELECT followee_id FROM f)
  ORDER BY p2.owned_by, p2.id DESC),
top_followees AS (
  SELECT owned_by
  FROM active
  ORDER BY last_id DESC LIMIT 20),
cand AS (
  SELECT pid.id
  FROM top_followees tf
  JOIN LATERAL (
    SELECT p2.id
    FROM posts p2
    WHERE p2.owned_by = tf.owned_by
    ORDER BY p2.id DESC LIMIT 20) AS pid ON TRUE),
top AS (
  SELECT id
  FROM cand
  ORDER BY id DESC OFFSET 0 LIMIT 20)
SELECT
  p.id, p.snippet, p.owned_by, p.reply_to,
  p.allow_likes, p.allow_replies, p.created_at, p.updated_at,
  u.nickname AS owner_nickname, pu.nickname AS reply_to_owner_nickname,
  p.count_replies AS count_replies, p.count_likes AS count_likes,
  ARRAY(SELECT pt2.name FROM post_tags pt2
    WHERE pt2.post_id = p.id ORDER BY pt2.name) AS tags
FROM top t
JOIN posts p ON p.id = t.id
JOIN users u ON p.owned_by = u.id
LEFT JOIN posts parent_post ON p.reply_to = parent_post.id
LEFT JOIN users pu ON parent_post.owned_by = pu.id
ORDER BY t.id DESC;
```

クエリが込み入っているので、部分ごとに解説しよう。

- フォローしているユーザのIDの一覧をfというビューとして作る。
- fの各々について最新の投稿IDを紐づけたactiveというビューを作る。
- activeの内容を投稿IDでソートして、最も最近に投稿をしたトップ20人のユーザIDの集合であるtop_followeesというビューを作る。
- top_followeesの各ユーザIDにJOIN LATERALして、各ユーザの最新投稿IDを20件ずつ取り出したcandというビューを作る。
- candの最大400件の投稿IDをソートして、最新20件に絞ったtopというビューを作る。
- topの各々のIDに対して、listPostsと同様に、各種属性を肉付けする。

これの計算量を考えよう。全ユーザ数をUと置き、全投稿数をPと置き、フォローしているユーザ数をFと置く。フォローしているユーザの一覧を引くのは、インデックスが利けば、O(log(U))だ。フォローしているユーザの各々の最新投稿を調べるのは、インデックスが利けば、O(F\*log(P))だ。F人から最新アクティブユーザ20人を選ぶのはtop-kヒープなので、O(F\*log(20)) で、20は定数なので、O(F)だ。最新アクティブユーザ20人の各々の最新投稿20件を取り出すと、400件が取れる。400件から20件を選ぶのもtop-kヒープなので、O(400\*log(20))で、400も20も定数なので、O(1)だ。そして20件の各々に肉付けする処理は、全てインデックスが利くなら、O(20\*log(P))で、20は定数なので、O(log(P))だ。つまり、UはPよりも少ないと仮定すると、全体の計算量の支配項はO(F\*log(P))ということになる。Pは莫大に大きくても大丈夫だし、Fはそこそこ大きくても大丈夫ということになる。ユーザ毎の最新投稿時刻をテーブルに分割して持っておくとO(F\*log(P))の項がO(F\*log(U))になって若干高速化するだろうが、そこまでする必要はないだろう。

あとは、各処理でちゃんとインデックスが効いているかどうかを確かめれば良い。上述のクエリをEXPLAINにかけてみると、以下の出力が得られる。全てがIndex Condの理想的な実行計画になっていることが確かめられた。

```:xsmall
Nested Loop Left Join (cost=9461.18..9727.60 rows=20 width=167)
 -> Nested Loop Left Join (cost=9460.90..9628.05 rows=20 width=145)
  -> Nested Loop (cost=9460.62..9619.31 rows=20 width=128)
    -> Nested Loop (cost=9460.35..9606.12 rows=20 width=121)
     -> Limit (cost=9460.06..9460.11 rows=20 width=17)
       -> Sort (cost=9460.06..9460.31 rows=100 width=17)
        Sort Key: p2_1.id DESC
        -> Nested Loop (cost=9369.04..9457.40 rows=100 width=17)
          -> Limit (cost=9368.75..9368.80 rows=20 width=34)
           -> Sort (cost=9368.75..9371.28 rows=1010 width=34)
             Sort Key: p2.id DESC
             -> Unique (cost=7.29..9341.88 rows=1010 width=34)
              -> Incremental Sort (cost=7.29..8918.21 rows=169466 width=34)
                Sort Key: p2.owned_by, p2.id DESC
                Presorted Key: p2.owned_by
                -> Nested Loop (cost=0.58..517.50 rows=169466 width=34)
                 -> Index Only Scan using user_follows_pkey on user_follows (cost=0.29..69.78 rows=1000 width=17)
                   Index Cond: (follower_id = '9901000000000001'::text)
                 -> Memoize (cost=0.29..0.58 rows=5 width=34)
                   Cache Key: user_follows.followee_id
                   Cache Mode: logical
                   -> Index Only Scan using idx_posts_owned_by_id on posts p2 (cost=0.28..0.57 rows=5 width=34)
                    Index Cond: (owned_by = (user_follows.followee_id)::text)
          -> Limit (cost=0.28..4.37 rows=5 width=17)
           -> Index Only Scan Backward using idx_posts_owned_by_id on posts p2_1 (cost=0.28..4.37 rows=5 width=17)
             Index Cond: (owned_by = (p2.owned_by)::text)
     -> Index Scan using posts_pkey on posts p (cost=0.28..7.30 rows=1 width=104)
       Index Cond: ((id)::text = (p2_1.id)::text)
    -> Index Scan using users_pkey on users u (cost=0.28..0.66 rows=1 width=24)
     Index Cond: ((id)::text = (p.owned_by)::text)
  -> Index Scan using posts_pkey on posts parent_post (cost=0.28..0.44 rows=1 width=34)
    Index Cond: ((id)::text = (p.reply_to)::text)
 -> Index Scan using users_pkey on users pu (cost=0.28..0.66 rows=1 width=24)
  Index Cond: ((id)::text = (parent_post.owned_by)::text)
 SubPlan 1
 -> Index Only Scan using post_tags_pkey on post_tags pt2 (cost=0.28..4.32 rows=2 width=6)
   Index Cond: (post_id = (p.id)::text)
```

## listPostsLikedByUser

自分がイイネした投稿の一覧を得るには、以下のクエリが使われる。

```sql:small
SELECT
  p.id, p.snippet, p.owned_by, p.reply_to,
  p.allow_likes, p.allow_replies, p.created_at, p.updated_at,
  u.nickname AS owner_nickname, pu.nickname AS reply_to_owner_nickname,
  p.count_replies AS count_replies, p.count_likes AS count_likes,
  ARRAY(SELECT pt.name FROM post_tags pt
    WHERE pt.post_id = p.id ORDER BY pt.name) AS tags
FROM post_likes pl
JOIN posts p ON pl.post_id = p.id
JOIN users u ON p.owned_by = u.id
LEFT JOIN posts pp ON p.reply_to = pp.id
LEFT JOIN users pu ON pp.owned_by = pu.id
WHERE pl.liked_by = '9901000000000001'
ORDER BY pl.created_at DESC OFFSET 0 LIMIT 20;
```

liked_byでの絞り込みにインデックスが利きさえすれば、計算量はlistPostsと同じくO(log(P))で済むはずだ。あとは実行計画見れば、それが確認できる。

```:xsmall
Limit (cost=1.40..26.01 rows=1 width=181)
 -> Nested Loop Left Join (cost=1.40..26.01 rows=1 width=181)
    -> Nested Loop Left Join (cost=1.12..17.36 rows=1 width=157)
       -> Nested Loop (cost=0.84..16.96 rows=1 width=140)
          -> Nested Loop (cost=0.56..16.60 rows=1 width=131)
             -> Index Scan Backward using idx_post_likes_liked_by_created_at on post_likes pl (cost=0.28..8.30 rows=1 width=25)
                Index Cond: ((liked_by)::text = '9901000000000001'::text)
             -> Index Scan using posts_pkey on posts p (cost=0.28..8.30 rows=1 width=123)
                Index Cond: ((id)::text = (pl.post_id)::text)
          -> Index Scan using users_pkey on users u (cost=0.28..0.36 rows=1 width=26)
             Index Cond: ((id)::text = (p.owned_by)::text)
       -> Index Scan using posts_pkey on posts pp (cost=0.28..0.40 rows=1 width=34)
          Index Cond: ((id)::text = (p.reply_to)::text)
    -> Index Scan using users_pkey on users pu (cost=0.28..0.36 rows=1 width=26)
       Index Cond: ((id)::text = (pp.owned_by)::text)
    SubPlan 1
     -> Index Only Scan using post_tags_pkey on post_tags pt (cost=0.28..8.30 rows=1 width=5)
        Index Cond: (post_id = (p.id)::text)
```

## listUsers

usersテーブルを操作するusersServiceという実装にも各種メソッドがあって、それぞれクエリを発行している。どれも軽い処理だが、ユーザの一覧を出すlistUsersだけは、注意を要する。例えば、ユーザのニックネームの前方一致条件で絞り込みを行いつつ、フォロイーもしくはフォロワーを優先して表示するという特殊機能がある。そのクエリは以下のものだ。

```sql:small
SELECT
  u.id, u.email, u.nickname, u.is_admin, u.snippet, u.avatar,
  u.ai_model, u.created_at, u.updated_at
FROM users u
LEFT JOIN user_follows f1 ON
  f1.follower_id = '9901000000000001' AND f1.followee_id = u.id
LEFT JOIN user_follows f2 ON
  f2.follower_id = u.id AND f2.followee_id = '9901000000000001'
WHERE LOWER(u.nickname) LIKE 'user2%'
ORDER BY
  (u.id = '9901000000000001') DESC,
  (f1.follower_id IS NOT NULL) DESC,
  (f2.follower_id IS NOT NULL) DESC,
  u.id ASC OFFSET 0 LIMIT 20;
```

LIKE演算子による前方一致は、インデックスが利くので、絞り込みを効率的に行うことができる。また、フォロー関係の結合はビットマップインデックスとハッシュジョインで絞り、最後にソートで順位付けするため、ヒット件数が少なければ高速に動く。EXPLAIN文の結果は以下である。

```:xsmall
Limit (cost=494.27..494.32 rows=20 width=487)
 -> Sort (cost=494.27..494.55 rows=112 width=487)
    Sort Key: (((u.id)::text = '9901000000000001'::text)) DESC, ((f1.follower_id IS NOT NULL)) DESC, ((f2.follower_id IS NOT NULL)) DESC, u.id
    -> Hash Right Join (cost=360.65..491.29 rows=112 width=487)
       Hash Cond: ((f2.follower_id)::text = (u.id)::text)
       -> Bitmap Heap Scan on user_follows f2 (cost=20.04..145.53 rows=1000 width=17)
          Recheck Cond: ((followee_id)::text = '9901000000000001'::text)
          -> Bitmap Index Scan on idx_user_follows_followee_created_at (cost=0.00..19.79 rows=1000 width=0)
             Index Cond: ((followee_id)::text = '9901000000000001'::text)
       -> Hash (cost=339.21..339.21 rows=112 width=501)
          -> Hash Right Join (cost=267.08..339.21 rows=112 width=501)
             Hash Cond: ((f1.followee_id)::text = (u.id)::text)
             -> Index Only Scan using user_follows_pkey on user_follows f1 (cost=0.29..69.78 rows=1000 width=34)
                Index Cond: (follower_id = '9901000000000001'::text)
             -> Hash (cost=265.39..265.39 rows=112 width=484)
                -> Bitmap Heap Scan on users u (cost=9.40..265.39 rows=112 width=484)
                   Filter: (lower((nickname)::text) ~~ 'user2%'::text)
                   -> Bitmap Index Scan on idx_users_nickname_id (cost=0.00..9.38 rows=110 width=0)
                      Index Cond: ((lower((nickname)::text) ~>=~ 'user2'::text) AND (lower((nickname)::text) ~<~ 'user3'::text))
```

さて、多くの処理がインデックスを使って行われているので、このクエリは一見速そうだ。実際、絞り込みの文字列が十分に長くてヒット件数が少ない場合には、最下層の文字列インデックスが効率的に働いて、少ない数のレコードを一瞬で返し、ハッシュマップを使って各々のレコードに効率的にスコアリングを施した上で、一瞬で処理を返してくれるだろう。問題は、絞り込みの文字列が短く、ヒット数が多い場合である。その場合、ヒットしたレコードの全てにスコアリングをしてからソートすることになるため、遅くなる。全ユーザ数をUとした場合、絞り込み文字列が1文字なら、Uの何割かがヒットしてしまうので、空間計算量はO(U)となる。それをtop-kヒープでソートする時間計算量は、kが20と小さいので、O(U)である。

なお、LIKE演算子による前方一致検索を効率的に動かすには、ちょっとしたコツがある。DBを作る際に、`POSTGRES_INITDB_ARGS: "--encoding=UTF8 --locale=C --lc-collate=C --lc-ctype=C"` などと指定して、コレーションを無効化することだ。Postgresのデフォルトでは文字列の比較を厳密なバイト比較ではなく、複数の文字を同一視するコレーションをした上で比較する。コレーションがあると、デフォルトのインデックスがLIKE演算子で使えない。その他の場面でも、コレーションのせいで効率が悪化することがありうるので、特にコレーションの要望がない限りは、コレーションは切っておいた方が無難だ。

コレーションを無効化したとしても、大文字と小文字の違いを無視するILIKE演算子には、デフォルトのインデックスは使えない。よって、nicknameのインデックスは `LOWER(nickname) text_pattern_ops` として小文字に正規化したものにしている。小文字に正規化したインデックスを十全に働かせるには、上述のクエリのように、クエリ内の条件も小文字に正規化する必要がある。そうでない場合、インデックスが使われない。

```x:small
# explain SELECT id, nickname FROM users WHERE LOWER(nickname) LIKE 'user2%' ORDER BY ID LIMIT 3;

Limit (cost=12.47..12.48 rows=3 width=24)
 -> Sort (cost=12.47..12.75 rows=112 width=24)
    Sort Key: id
    -> Index Only Scan using idx_users_nickname_id on users (cost=0.28..11.03 rows=112 width=24)
       Index Cond: (((lower((nickname)::text)) ~>=~ 'user2'::text) AND ((lower((nickname)::text)) ~<~ 'user3'::text))
       Filter: ((lower((nickname)::text)) ~~ 'user2%'::text)

# explain SELECT id, nickname FROM users WHERE nickname LIKE 'user2%' ORDER BY ID LIMIT 3;
Limit (cost=0.28..18.67 rows=3 width=24)
 -> Index Scan using users_pkey on users (cost=0.28..686.93 rows=112 width=24)
    Filter: ((nickname)::text ~~ 'user2%'::text)
```

# listFriendsByNicknamePrefix

さて、上述のlistUsersメソッドは、それに与えられた外部仕様を満たすためには最善の実装ではあるが、SNSの実運用に供するには効率が悪すぎる。そこで、仕様を単純化したlistFriendsByNicknamePrefixという専用メソッドを設けた。ユーザリストはIDの昇順か降順で返すという原則を崩して、自分、フォロイー、その他の分類順で、各分類の中ではニックネームの辞書順にするという特殊仕様だ。あまりこういう専用メソッドを作りたくはないのだが、こればっかりはやらないと仕方がない。基本戦略としては、自分、フォロイー、その他大勢、を別々に処理して絞り込んでから、最後にUNION ALL結合する。具体的なクエリは以下のものだ。

```sql:small
WITH
  self AS (
    SELECT
      0 AS prio,
      u.id, lower(u.nickname) AS nkey
    FROM users u
    WHERE u.id = '9901000000000001' AND lower(u.nickname) LIKE 'user2%' ),
  followees AS (
    SELECT
      1 AS prio, u.id, lower(u.nickname) AS nkey
    FROM user_follows f
    JOIN users u ON u.id = f.followee_id
    WHERE f.follower_id = '9901000000000001' AND lower(u.nickname) LIKE 'user2%'
    ORDER BY lower(u.nickname), u.nickname, u.id LIMIT 20 ),
  others AS (
    SELECT
      3 AS prio, u.id, lower(u.nickname) AS nkey
    FROM users u
    WHERE lower(u.nickname) LIKE 'user2%'
    ORDER BY lower(u.nickname), u.nickname, u.id LIMIT 20 ),
  candidates AS (
    SELECT * FROM self
    UNION ALL
    SELECT * FROM followees
    UNION ALL
    SELECT * FROM others ),
  dedup AS (
    SELECT DISTINCT ON (id)
      id, prio, nkey
    FROM candidates
    ORDER BY id, prio ),
  page AS (
    SELECT
      id, prio, nkey
    FROM dedup
    ORDER BY prio, nkey, id OFFSET 0 LIMIT 20 )
SELECT
  u.id, u.email, u.nickname, u.is_admin, u.snippet, u.avatar,
  u.ai_model, u.created_at, u.updated_at
FROM page p
JOIN users u ON u.id = p.id
ORDER BY p.prio, p.nkey, u.id;
```

selfとfolloweesとothersの3つの枝のそれぞれで最大20件のレコードだけを取り出していて、それぞれが20件だけのスキャンで早期終了することを企図している。取り出すレコードも優先度とIDとニックネームだけの最低限に絞っている。そして、dedup処理では、id, prio, nkeyでソートしてから重複IDを除いていて、prioの最小値が採択されている。最後に最終順序でソートした20件だけに他の属性を肉付けして返している。

これの計算量を考えよう。全ユーザ数をUと置き、フォロイー数をFと置く。自分を調べるのは、O(log(U))だ。フォロイーの一覧を引くのは、O(log(U\*F)+F)だ。検索文字列が短い場合、ほとんど絞り込みが働かないので、フォロイー全員のニックネームを調べることになる。よって、その計算量はO(F\*log(U))だ。フォロイーのヒット全てを並び替える計算量はO(F\*log(F))だ。全員を調べる枝では、検索文字列が短い場合でも、確実に早期終了するので、計算量はO(log(U))だ。つまり、FはUより十分に小さいと仮定すると、支配項はO(F\*log(U))ということになる。EXPLAIN文の結果は以下である。全ての枝（Subquery）でIndex Condが働いていて、早期終了するので、効率は最善だ。フォロイーの枝でフォロイー毎にレコードを調べているのもわかる。

```:xsmall
Nested Loop (cost=114.05..247.88 rows=20 width=520)
 -> Limit (cost=113.77..113.82 rows=20 width=53)
  -> Sort (cost=113.77..113.87 rows=41 width=53)
    Sort Key: "*SELECT* 1".prio, "*SELECT* 1".nkey, "*SELECT* 1".id
    -> Unique (cost=112.48..112.68 rows=41 width=53)
     -> Sort (cost=112.48..112.58 rows=41 width=53)
       Sort Key: "*SELECT* 1".id, "*SELECT* 1".prio
       -> Append (cost=0.28..111.38 rows=41 width=53)
        -> Subquery Scan on "*SELECT* 1" (cost=0.28..8.31 rows=1 width=53)
          -> Index Scan using users_pkey on users u_1 (cost=0.28..8.30 rows=1 width=53)
           Index Cond: ((id)::text = '9901000000000001'::text)
           Filter: (lower((nickname)::text) ~~ 'user2%'::text)
        -> Subquery Scan on followees (cost=88.08..88.33 rows=20 width=53)
          -> Limit (cost=88.08..88.13 rows=20 width=60)
           -> Sort (cost=88.08..88.35 rows=111 width=60)
             Sort Key: (lower((u_2.nickname)::text)), u_2.nickname, u_2.id
             -> Hash Join (cost=12.71..85.12 rows=111 width=60)
              Hash Cond: ((f.followee_id)::text = (u_2.id)::text)
              -> Index Only Scan using user_follows_pkey on user_follows f (cost=0.29..69.78 rows=1000 width=17)
                Index Cond: (follower_id = '9901000000000001'::text)
              -> Hash (cost=11.03..11.03 rows=112 width=24)
                -> Index Only Scan using idx_users_nickname_id on users u_2 (cost=0.28..11.03 rows=112 width=24)
                 Index Cond: (((lower((nickname)::text)) ~>=~ 'user2'::text) AND ((lower((nickname)::text)) ~<~ 'user3'::text))
                 Filter: ((lower((nickname)::text)) ~~ 'user2%'::text)
        -> Subquery Scan on others (cost=14.29..14.54 rows=20 width=53)
          -> Limit (cost=14.29..14.34 rows=20 width=60)
           -> Sort (cost=14.29..14.57 rows=112 width=60)
             Sort Key: (lower((u_3.nickname)::text)), u_3.nickname, u_3.id
             -> Index Only Scan using idx_users_nickname_id on users u_3 (cost=0.28..11.30 rows=112 width=60)
              Index Cond: (((lower((nickname)::text)) ~>=~ 'user2'::text) AND ((lower((nickname)::text)) ~<~ 'user3'::text))
              Filter: ((lower((nickname)::text)) ~~ 'user2%'::text)
 -> Index Scan using users_pkey on users u (cost=0.28..6.69 rows=1 width=484)
  Index Cond: ((id)::text = ("*SELECT* 1".id)::text)
```

## 総評

ここまで見てきたように、記事IDやユーザIDのリストを取得するための検索操作は全てインデックス上で行えるように、スキーマとクエリを設計している。各々のインデックスは小さいので、大部分がメモリ上にキャッシュされて、高速にランダムアクセスできる。よって、Fakebookの主要クエリは、全てスケールするものになっていると言える。

全体の最新投稿を一覧で使うlistPostsの計算量はO(log(P))だ。自分がフォローしているユーザの最新投稿を一覧で使うlistPostsByFolloweesの計算量はO(F\*log(P))で済んでいる。イイネした投稿の一覧で使うlistPostsLikedByUserの計算量はO(log(P))だ。その他、全ての投稿一覧はO(log(P))以下の計算量に留めている。ユーザ一覧に関しても同様で、全文検索以外で最も重いlistFriendsByNicknamePrefixの計算量もO(F\*log(U))に留めている。

最も重いlistPostsByFolloweesとlistFriendsByNicknamePrefixの計算量はフォロイー数Fに比例する。したがって、フォロイー数を定数項にするために、上限値を決める必要がある。現実的には100人以上フォローしても使い勝手が悪くなるだけなので、200人くらいを上限値にすれば問題ないだろう。Fが定数であれば、計算量はO(log(P))とO(log(U))と表せるわけで、だれがどう見ても健全なシステムになる。

投稿記事の本文やユーザ自己紹介の本文などのでかいデータを取得する操作も、スケーラビリティの制限要因になる。主キーに紐づいたテーブル本体のレコードを読み出すという操作は、レコード数Nに対してO(log(N))の計算量に過ぎない。しかし、データの規模が大きいと遅くなる。メモリ上のキャッシュに乗り切らないので、毎回のアクセスでストレージにアクセスするからだ。HDDであればシークタイムも加算される。読み出しのデータが大きいと、ストレージとメモリの間のデータ転送量が増えることでも遅くなる。postsとusersテーブルに本文を入れずにスニペットだけを入れるのは、この問題に対する緩和策だ。

## 余談

スニペットをDBに保存するということは、「どう表示するか」というフロントエンド側のプレゼンテーションの知識をバックエンド側で持つことを意味するため、責任分割の観点では気持ち悪い。スニペットの形式や文字数制限を変えた際にDBのレコードを入れ直さなきゃならないのも嫌だ。しかし、その気持ち悪さを飲んでもやらねばならない。

投稿記事やユーザ自己紹介の本文を分離するという手法は、いわゆる垂直分散の一種である。属性データの特性に合わせて管理方法を分割する手法とも言える。本文だけDBサーバを分けてもいいし、列指向DBに入れてもいいし、S3に入れてクライアントに直接取得させたっていい。古い記事の本文は圧縮した上でアーカイブ用のストレージに入れてもいい。post_likesやuser_followsといったテーブルを別サーバで管理するのも良いだろう。

以上のことを鑑みると、リソースのリストを取得する処理は、常に二段構えで考えるべきだ。条件に該当するIDのリストを生成する段と、そのIDに紐づけて属性を収集する段だ。RDB1台運用だとその2段が一発のクエリでできるが、それでもサブクエリを使って敢えて2段に分けて書くのも良い考えだ。以下の二つのクエリは等価で、後者の方が若干遅いかもしれないが、いずれ垂直分散する際は、後者の書き方をしておく方がバグりにくい。

```sql:small
SELECT id, nickname, introduction
FROM USERS WHERE id > '0001000000000002'
ORDER BY id LIMIT 10;

WITH cand_ids AS (
  SELECT id FROM users
  WHERE id > '0001000000000002'
  ORDER BY id LIMIT 10
)
SELECT u.id, u.nickname, u.introduction
FROM users AS u
JOIN cand_ids AS c ON u.id = c.id
ORDER BY c.id;
```

なお、PostgreSQLでは、TOASTという機能があり、2KB以上の大きい列データを暗黙的に圧縮したり別テーブルに移動したりして、個々のレコードが単一ページに収まるように努力してくれる。よって、明示的に分割しなくても、ある程度の最適化は勝手になされる。しかし、それでもなお、大きさや参照頻度が異なるデータは明示的に分割した方が良い。今回の例では、スニペットさえあればリスト取得時には本文を一切参照する必要がないので、短くても長くても別テーブルにした方が、主テーブルのページ読み出し量が少なくて済む。

![TOAST図解](/data/help-postgres-toast.png){size=large}

指定した列の短いデータも強制的にTOASTしてくれれば、わざわざテーブル分割しなくても済むのにと思ったが、そのような指定はできない。また、テーブル分割した先では、TOASTしなくてもよいとも思ったが、そのような指定もできない。TOASTの本来の目的は参照局所性の向上ではなく、主テーブルの各レコードのサイズをページサイズ（8KB）以下に抑えることだからだ。なお、TOASTは圧縮もしてくれるが、そのデフォルトの圧縮方式はpglz（LZ77）で、遅い割には圧縮率があまり良くない。なので、今回はDB全体の圧縮設定をLZ4に変更している。LZ4は無圧縮に近い速度で動く割には、自然言語の文字列を半分くらいに圧縮する能力があるので、LZ4に変更する利点は大きい。

垂直分割をしても処理しきれなくなってきたら、いよいよ水平分割をすることになる。ユーザIDを使ってパーティショニングを行うのが率直な方法だろう。ハッシュ値などで機械的に割り振っても良いが、各ユーザがどのパーティションに居るのかを管理するuser_partitionsテーブルを作るか、それに相当するKVSを運用するのが率直だ。usersテーブルを引く時はユーザIDでパーティションを特定してからそのDBサーバにアクセスし、postsテーブルを引く時は著者のユーザIDでパーティションを特定してからそのDBサーバにアクセスする。フォロー関係は、フォロー元のユーザとフォロー先のユーザのDBに二重化して持たせれば良い。垂直分割を経ているならば、もはやJOINするクエリは少なくなっていて、IDのリストを取り出してから別のDBにアクセスする作法は確立しているはずだ。あとはそのアクセス先を個々のIDに紐づいたパーティションにするだけだ。ユーザに紐づいた一連のデータをパーティション間で移動するユーティリティさえ書いておけば、運用はそんなに難しくない。

規模が大きくなると、投稿一覧の「All」のビューがほとんど意味をなさなくなってくる。見知らぬ人の投稿を全て見る奴は居ない。となると、「Pickup」とか「Topics」とかいう位置づけのビューを代わりに置くことになるだろう。最近の投稿だけを集めた小さいデータベースを作っておいて、質が高いものや個々のユーザの興味に近そうなものをバッチ処理で計算して、それを提示するのだ。

ここまでいろいろ述べたが、Fakebookの現状の目標は、スケーラビリティを追求することではない。SNSの基本機能を率直に実装した、シンプルで典型的で教科書的なシステムを作ることだ。少なくとも開発の初期段階では、見通しがよく開発と保守がしやすいスキーマを選択すべきで、現状のスキーマはそれに叶うものになっている。時期尚早の最適化をして、人気が出る前に開発が頓挫するというのでは意味がないので、シンプルな構成から始めるというのも重要だ。

Next: [Fakebookのメディアストレージ](/posts/0002000000000014)
____EOF____
