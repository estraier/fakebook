id: 0002000000000014
ownedBy: 0001000000000002
allowLikes: false
allowReplies: false
tags: fakebook-help
content:<<____EOF____
# Fakebookのメディアストレージ

本記事では、Fakebookにおいて画像などのメディアデータをどのように管理するかについて説明する。Amazon S3または互換システムであるMinIOのAPIを使って単純かつ堅牢なデータ管理をするにはどうするかについて述べる。

## 前提条件

画像などのメディアデータを扱う場合、データベースにバイナリを入れたり、ファイルシステムにファイルを置いたりする方法だと、運用が面倒くさい。可用性の確保や容量制限やバックアップの作成に独自の手順を必要とするからだ。それよりは、いわゆるクラウドストレージを使ったほうが楽だ。

FakebookではストレージサービスとしてAmazon S3（Simple Storage Service）を使うことにしていて、開発中はMinIOのDockerインスタンスを立ててS3のエミュレーションをしている。ここではその構成でのデータ管理の概要について述べる。また、開発環境および本番環境での構築と運用についても述べる。

## S3のデータ管理の概要

S3は、バケットという単位の中に任意の名前付きオブジェクトを格納する仕組みである。言い換えると、バケット毎にkey-valueストアがあり、キーがファイル名、valueがオブジェクトのバイナリということになる。キーには "/" で区切ったディレクトリ構造を模した文字列を使うことが通例だが、"/" に特別な意味はなく、オブジェクトはキーの完全一致で識別されるとともに、キーの前方一致によるリスト機能が提供されるだけである。

投稿内に埋め込む画像は "fakebook-images" バケット内に置かれる。その中に、以下の構造でオブジェクトが置かれる。元画像はクライアントから直接アップロードされ、サムネイルはシステム側で自動的に作られる。

- {userId}/masters/{revYYYYMM}/{time8}{hash8}.{ext}
- {userId}/thumbs/{revYYYYMM}/{time8}{hash8}_image.webp

`{userId}` はユーザIDである。`{revYYYYMM}` は、作成日時のYYYYMM値を999999から引いた値である。`{time8}` は月内のタイムスタンプを最大値から引いた8桁の16進数である。`{hash8}` は衝突回避のための8桁の16進数である。以下に例を示す。`{ext}` は画像形式に対応する拡張子である。

- 0001000000000002/masters/797491/8244600348025c20d1da7.jpg
- 0001000000000002/thumb/797491/8244600348025c20d1da7_image.webp

S3では、キーは文字列の辞書順で並べられる。前方一致検索ができるので、キーにユーザIDを接頭させると、ユーザごとのオブジェクトを検索できるようになる。また、その後に固定長の日付をつければ、ユーザ毎に日付の順番にオブジェクトが並べられることになる。逆順に辿るAPIは無いので、新しい順で見たい場合には、日付の最大値から現在の日付を引いた値を使えば良いことになる。また、YYYYMMを単位とすることで、月ごとにオブジェクトが分類できるので、月のクォータ管理ができる。

アバター画像など、個々のユーザが一つずつしか持たないプロファイル系の画像は、"fakebook-profiles" というバケット内に置かれる。その中に、以下の構造でオブジェクトが置かれる。元画像はクライアントから直接アップロードされ、サムネイルはシステム側で自動的に作られる。

- {userId}/masters/{type}.{ext}
- {userId}/thumbs/{type}_icon.webp

`{userId}` はユーザIDである。`{type} は、データの種類を表すが、現状では "avatar" のみである。`{ext}` は画像形式に対応する拡張子である。以下に例を示す。

- 0001000000000002/masters/avatar.png
- 0001000000000002/thumbs/avatar_icon.webp

プロファイル系の画像は、ユーザと種別ごとに単一なので、画像単体のサイズのみが制限され、クォータの制限はない。

以上の命名規則によって、DBでキーやメタデータを管理することなく、ストレージサービスのみで、メディアデータを管理することができる。

## S3単体管理 vs DBでのメタデータ管理

どのユーザがどのファイルを登録したかというメタデータをDBのテーブルで管理すれば、キーの前方一致検索しかできないというS3の制限に対する回避策は必要なくなる。しかし、そうしないと行けないという理由がないのなら、DBでのメタデータ管理は導入したくない。S3側とDB側にまたがるトランザクションの整合性を確保するのが結構面倒くさいからだ。例えば新しいオブジェクトを登録するなら、DB側にメタデータを入れる予約をして、それに基づいてS3にオブジェクトを作って、成功したらメタデータを確定させるという処理になる。そのそれぞれの過程の中間状態でシステムクラッシュが起きうるので、予約状態のメタデータに対応するS3オブジェクトを破棄したり、予約状態のメタデータを破棄したりといったゴミ掃除も必要になる。

S3単体だと、中間状態がないので、管理が簡単だ。オブジェクトの登録・更新・削除の処理の原子性はS3が確保してくれるので、それ以外のデータとの整合性を気にしなくて良いならば、面倒くさい多層コミット的な処理は必要ないし、明示的なゴミ掃除も必要ない。ただし、それはS3の貧弱な検索機能を受け入れるという意味でもある。リスト表示機能は、予め決めておいた単一の順序でしか行えない。今回はファイルを新しい順に表示するUIだけを提供すると割り切っている。古いファイルを探すには何ページもめくってサムネイルを眺める必要がある。アップロードしたデータのローカルでのファイル名は失われているので、ファイル名で文字列検索することもできない。

SNSでの画像置き場としての利用では、S3単体で問題ないと判断している。基本的には記事を執筆するUIで画像をアップロードして、その瞬間に画像を参照するマーカーが記事に埋め込まれるので、画像単体を検索できる必要はあまりない。記事の方を検索すればよいのだ。ほとんどのユーザは、メールやメッセージアプリの添付ファイルのようなノリで画像を記事に貼り付けて、その記事を関係者に閲覧させる。そしてその記事の賞味期限が過ぎたら、貼り付けた画像のことは忘れてしまう。わざわざ古い画像を検索して再利用した記事を書く頻度は低いだろう。記事を消したとしても、そこで使った画像をわざわざ消すような律儀なユーザはほとんどいないだろう。なので、新しい順で画像一覧が表示できて、かつユーザごとの容量管理ができれば良く、それらはS3単体で実現できる。

## 画像アップロード処理

画像をS3にアップロードするにあたっては、一定のプロトコルが必要になる。巨大なデータをS3にアップロードするとなると、バックエンドサーバが一旦データを預かってからS3に転送するという方法は取りたくない。よって、クライアントが直接S3にデータをアップロードすることになるが、好き勝手にアップロードさせるわけには行かない。そこで、最初に、「どのキーにどんなデータをアップロードするか」を決めて、それを示すpresignをS3に発行させる。実際には、ステージング領域にデータをアップロードするというpresignを作る。そして、クライアントにpresignを渡し、クライアントはpresignのトークンを使って、許可されたアップロード操作をS3に行う。それが完了したら、バックエンド側の責任で、ステージング環境のデータを本番環境に移動させる。具体的な流れを以下に箇条書きする。

- ユーザは、ローカルファイルシステムから、アップロードしたいファイルを選ぶ。
- クライアントは、アップロードするファイルの情報をバックエンドに送る。
- バックエンドは、S3直PUTの署名付きPOST情報のpresignをS3から取得し、クライアントに返す。
  - ファイル単体のサイズが制限値（10MB）以下か確認する。
  - 新規のファイルサイズと当月全ての登録ファイルの合計が月間クォータの制限内か確認する。
  - 拡張子に対応するMIMEタイプがJPEG、PNG、WEBP、HEICのどれかであるか確認する。
- クライアントは、署名情報に基づき、S3のステージング領域へ直接アップロードする。
- クライアントは、バックエンドに操作完了を報告する。
- バックエンドは、ステージング領域のデータを本番領域に移動させる。
  - パスがステージング領域のものか確認する。
  - 単体のデータサイズと月間クォータが制限値以内か確認する。
  - ファイルの先頭データを見て、ファイル形式を判定する。
  - エラーがあれば、ステージングのデータを削除して終了する。
- バックエンドは、登録画像に対応するサムネイルを作るジョブキューをRedisに登録する。
- メディアワーカーは、ジョブキューを読んで非同期的にサムネイルを作成する。

## その他の処理

画像を削除する際には、マスター画像を削除するとともに、サムネイルも削除する。

画像を一覧する際には、


Redis キュー media-thumb-queue に { type: "image", bucket, originalKey } を push。

一覧時は masters/{revMM}/ を前方一致で見る。revMM と r8 の逆順化により 辞書順＝新しい順 を維持できる。

3) サムネイル

サムネは thumbs/{revMM}/{r8}{hash8}_{WxH}.webp のように サイズ別に複数生成（_icon 固定名ではない）。

画像削除時は、マスターの {revMM} とファイル名（拡張子除去）から _{…} で始まる全サムネを一括削除。

4) 一覧・取得・削除（投稿画像）

一覧: listImages(userId, offset, limit)
/{userId}/masters/ を前方一致でページング。

取得: getImageBytes(userId, keyWithoutUserPrefix)
/{userId}/masters/… または /{userId}/thumbs/… のみ許可。staging は拒否。

削除: deleteImage(userId, keyWithoutUserPrefix)
マスター削除後、対応する thumbs の 該当サイズを全削除。

5) プロファイル画像（アバター等）

presign: presignProfileUpload(userId, slot, filename, sizeBytes, sizeLimitBytes?)
profiles-staging/{userId}/{slot}/{UUID}.{ext} に対する署名付きPOST。
月間上限なし（単体サイズ制限のみ）。

finalize: finalizeProfile(userId, slot, stagingKey, sizeLimitBytes?)
スニフ → /{userId}/masters/{slot}.{ext} に move →
Redis に { type: "icon", bucket, originalKey } を push。
サムネは /{userId}/thumbs/{slot}_{WxH}.webp という サイズ別複数。

取得/削除
取得は masters/{slot}.* をリストして現物を読む。
削除はマスターを消し、thumbs/{slot}_* をまとめて削除。

6) 月間クォータ

calculateMonthlyQuota(userId, yyyymm?)

対象月の revMM を計算し、masters/{revMM}/ と thumbs/{revMM}/ の合計バイトを算出。

返り値に単体上限/月間上限も含め、UI から現状と残量を表示できる。

7) セキュリティと失敗時の挙動

ユーザ配下パスの強制（isKeyUnder）で 越境アクセスを遮断。

staging 直読み不可。

サイズ/フォーマットに失敗したら staging を必ず削除 して終了（中間ゴミを残さない）。

拡張子は スニフ優先で偽装に強い。

8) クライアント実装の注意

署名の有効期限は5分。すぐにアップロードする。

finalize 後すぐは、サムネ生成が未完の場合あり。
必要に応じて マスターを表示するか、軽いリトライでサムネの出現を待つ。
（例：アバター更新でリトライしていた waitForAvatarReady）

この仕様で、S3のみで完全管理（DB不要）、新しい順表示と月次クォータ、安全な検証・清掃まで一貫して担保できます。














## 本番環境での設定

メディア関係の設定も環境変数で管理されている。開発中には.envファイルを使い、MinIO前提の設定が書いてある。本番環境では、バックエンドとフロントエンドに渡す環境変数をS3用に書き換えることになる。

バックエンドに渡す環境変数は以下のものである。

- FAKEBOOK_STORAGE_DRIVER : 現状、"s3" 決め打ち
- FAKEBOOK_STORAGE_S3_ENDPOINT : S3のAPIを叩くエンドポイント
- FAKEBOOK_STORAGE_S3_REGION : リージョンの識別子
- FAKEBOOK_STORAGE_S3_ACCESS_KEY_ID : S3を使うAWSのアカウントID
- FAKEBOOK_STORAGE_S3_SECRET_ACCESS_KEY : S3のアクセスパスワード（秘匿情報）
- FAKEBOOK_STORAGE_S3_FORCE_PATH_STYLE : 公開URLの "ENDPOINT/BUCKET/KEY" と "BUCKET.ENDPOINT/KEY" の切り替え
- FAKEBOOK_STORAGE_S3_BUCKET_PREFIX : バケット名の接頭辞
- FAKEBOOK_STORAGE_S3_PUBLIC_BASE_URL : 公開URLの接頭辞

本番環境では、以下の設定が無難である。

- FAKEBOOK_STORAGE_DRIVER=S3
- FAKEBOOK_STORAGE_S3_ENDPOINT= (空文字列にすると自動選択される）
- FAKEBOOK_STORAGE_S3_REGION=
- FAKEBOOK_STORAGE_S3_ACCESS_KEY_ID :
- FAKEBOOK_STORAGE_S3_SECRET_ACCESS_KEY :
- FAKEBOOK_STORAGE_S3_FORCE_PATH_STYLE :
- FAKEBOOK_STORAGE_S3_BUCKET_PREFIX :
- FAKEBOOK_STORAGE_S3_PUBLIC_BASE_URL :










```
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "AllowGetFromOurSite",
      "Effect": "Allow",
      "Principal": "*",
      "Action": ["s3:GetObject"],
      "Resource": [
        "arn:aws:s3:::fakebook-images/*",
        "arn:aws:s3:::fakebook-profiles/*"
      ],
      "Condition": {
        "StringLike": {
          "aws:Referer": [
            "https://fakebook.example/*",
            "https://www.fakebook.example/*"
          ]
        }
      }
    },
    {
      "Sid": "AllowGetWhenRefererIsEmpty",
      "Effect": "Allow",
      "Principal": "*",
      "Action": ["s3:GetObject"],
      "Resource": [
        "arn:aws:s3:::fakebook-images/*",
        "arn:aws:s3:::fakebook-profiles/*"
      ],
      "Condition": {
        "Null": { "aws:Referer": "true" }
      }
    }
  ]
}
```


Next: [Fakebookの通知機能](/posts/0002000000000015)
____EOF____
